âœ… Job started at: Thu May  8 10:13:29 CEST 2025
============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
2025-05-08 10:13:36.558525: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-05-08 10:13:36.719778: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-05-08 10:13:36.719888: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-05-08 10:13:36.735563: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-05-08 10:13:36.774206: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/home/pnair/.local/lib/python3.11/site-packages/onnxscript/converter.py:816: FutureWarning: 'onnxscript.values.Op.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.
  param_schemas = callee.param_schemas()
/home/pnair/.local/lib/python3.11/site-packages/onnxscript/converter.py:816: FutureWarning: 'onnxscript.values.OnnxFunction.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.
  param_schemas = callee.param_schemas()
/home/pnair/.local/lib/python3.11/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.6 (you have 1.4.14). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
=> merge config from /home/pnair/spai/configs/spai.yaml
[2025-05-08 10:13:44 finetune](__main__.py 218): INFO Full config saved to /home/pnair/spai/output/train/finetune/spai/config.json
[2025-05-08 10:13:46 finetune](__main__.py 221): INFO AMP_OPT_LEVEL: O2
AUG:
  AUTO_AUGMENT: rand-m9-mstd0.5-inc1
  BLUR_PROB: 0.25
  COLOR_JITTER: 0.0
  COLOR_JITTER_BRIGHTNESS_RANGE: &id001
  - 0.8
  - 1.2
  COLOR_JITTER_CONTRAST_RANGE: *id001
  COLOR_JITTER_HUE_RANGE:
  - -0.1
  - 0.1
  COLOR_JITTER_SATURATION_RANGE: *id001
  CUTMIX: 1.0
  CUTMIX_MINMAX: null
  GAUSSIAN_BLUR_LIMIT:
  - 3
  - 9
  GAUSSIAN_BLUR_PROB: 0.5
  GAUSSIAN_BLUR_SIGMA:
  - 0.01
  - 0.5
  GAUSSIAN_NOISE_PROB: 0.5
  HORIZONTAL_FLIP_PROB: 0.5
  JPEG_COMPRESSION_PROB: 0.5
  JPEG_MAX_QUALITY: 100
  JPEG_MIN_QUALITY: 50
  MAX_CROP_AREA: 1.0
  MIN_CROP_AREA: 0.2
  MIXUP: 0.8
  MIXUP_MODE: batch
  MIXUP_PROB: 1.0
  MIXUP_SWITCH_PROB: 0.5
  RECOUNT: 1
  REMODE: pixel
  REPROB: 0.25
  ROTATION_DEGREES: 90
  ROTATION_PROB: 0.5
  SHARPEN_ALPHA_RANGE:
  - 0.01
  - 0.4
  SHARPEN_LIGHTNESS_RANGE:
  - 0.95
  - 1
  SHARPEN_PROB: 0.0
  VERTICAL_FLIP_PROB: 0.5
  WEBP_COMPRESSION_PROB: 0.0
  WEBP_MAX_QUALITY: 100
  WEBP_MIN_QUALITY: 50
BASE:
- ''
DATA:
  AUGMENTED_VIEWS: 4
  BATCH_SIZE: 192
  BLUR:
    BETA_GAUSSIAN:
    - 0.5
    - 4
    BETA_PLATEAU:
    - 1
    - 2
    KERNEL_LIST:
    - iso
    - aniso
    - generalized_iso
    - generalized_aniso
    - plateau_iso
    - plateau_aniso
    - sinc
    KERNEL_PROB:
    - 0.405
    - 0.225
    - 0.108
    - 0.027
    - 0.108
    - 0.027
    - 0.1
    KERNEL_SIZE:
    - 7
    - 9
    - 11
    - 13
    - 15
    - 17
    - 19
    - 21
    ROTATE_ANGLE:
    - -3.1416
    - 3.1416
    SIGMA_X:
    - 0.2
    - 3
    SIGMA_Y:
    - 0.2
    - 3
  CSV_ROOT: /home/pnair/spai/datasets
  DATASET: csv_sid
  DATA_PATH: /home/pnair/spai/datasets/ldm_train_val_subset.csv
  FILTER_TYPE: mfm
  IMG_SIZE: 224
  INTERPOLATION: bicubic
  LMDB_PATH: None
  MASK_RADIUS1: 16
  MASK_RADIUS2: 999
  MIN_CROP_SCALE: 0.2
  NOISE:
    GAUSSIAN_GRAY_NOISE_PROB: 0.4
    GAUSSIAN_SIGMA:
    - 1
    - 30
    POISSON_GRAY_NOISE_PROB: 0.4
    POISSON_SCALE:
    - 0.05
    - 3
    PROB:
    - 0.5
    - 0.5
    TYPE:
    - gaussian
    - poisson
  NUM_WORKERS: 16
  PIN_MEMORY: true
  PREFETCH_FACTOR: 2
  SAMPLE_RATIO: 0.5
  SR_FACTOR: 8
  TEST_BATCH_SIZE: null
  TEST_DATA_CSV_ROOT: []
  TEST_DATA_PATH: []
  TEST_PREFETCH_FACTOR: 4
  VAL_BATCH_SIZE: 256
  VAL_PREFETCH_FACTOR: null
EVAL_MODE: false
LOCAL_RANK: 0
MODEL:
  CLS_HEAD:
    MLP_RATIO: 3
  DROP_PATH_RATE: 0.1
  DROP_RATE: 0.0
  FEATURE_EXTRACTION_BATCH: 400
  FRE:
    DISABLE_RECONSTRUCTION_SIMILARITY: false
    MASKING_RADIUS: 16
    ORIGINAL_IMAGE_FEATURES_BRANCH: true
    PROJECTOR_LAST_LAYER_ACTIVATION_TYPE: null
  FREQ_LOSS:
    AVE_SPECTRUM: false
    BATCH_MATRIX: false
    LOG_MATRIX: false
    LOSS_GAMMA: 1.0
    MATRIX_GAMMA: 1.0
    PATCH_FACTOR: 1
    WITH_MATRIX: false
  LABEL_SMOOTHING: 0.1
  NAME: finetune
  NUM_CLASSES: 2
  PATCH_VIT:
    ATTN_EMBED_DIM: 1536
    MINIMUM_PATCHES: 4
    NUM_HEADS: 12
    PATCH_STRIDE: 224
  RECOVER_TARGET_TYPE: normal
  REQUIRED_NORMALIZATION: positive_0_1
  RESNET:
    IN_CHANS: 3
    LAYERS:
    - 3
    - 4
    - 6
    - 3
  RESOLUTION_MODE: arbitrary
  RESUME: ''
  SEMANTIC:
    CROSS_ATTN_SCA: null
    EMBED_DIM: 137
    FREEZE_BACKBONE: true
    NUM_HEADS: 8
  SID_APPROACH: freq_restoration
  SID_DROPOUT: 0.5
  SWIN:
    APE: false
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    EMBED_DIM: 96
    IN_CHANS: 3
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    PATCH_NORM: true
    PATCH_SIZE: 4
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  TYPE: vit
  VIT:
    DECODER:
      DEPTH: 0
      EMBED_DIM: 512
      NUM_HEADS: 16
    DEPTH: 12
    EMBED_DIM: 768
    FEATURES_PROCESSOR: rine
    INIT_VALUES: null
    INTERMEDIATE_LAYERS:
    - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
    - 9
    - 10
    - 11
    IN_CHANS: 3
    MLP_RATIO: 4
    NUM_HEADS: 12
    PATCH_POOLING: mean
    PATCH_PROJECTION: true
    PATCH_PROJECTION_PER_FEATURE: true
    PATCH_SIZE: 16
    PROJECTION_DIM: 1024
    PROJECTION_LAYERS: 2
    QKV_BIAS: true
    USE_APE: true
    USE_FPE: false
    USE_INTERMEDIATE_LAYERS: true
    USE_MEAN_POOLING: true
    USE_RPB: false
    USE_SHARED_RPB: false
MODEL_WEIGHTS: mfm
OUTPUT: /home/pnair/spai/output/train/finetune/spai
PRETRAINED: /home/pnair/spai/weights/mfm_pretrain_vit_base.pth
PRINT_FREQ: 100
SAVE_FREQ: 10
SEED: 0
TAG: spai
TEST:
  CROP: true
  EXPORT_IMAGE_PATCHES: false
  GAUSSIAN_BLUR: false
  GAUSSIAN_BLUR_KERNEL_SIZE: 3
  GAUSSIAN_NOISE: false
  GAUSSIAN_NOISE_SIGMA: 1.0
  JPEG_COMPRESSION: false
  JPEG_QUALITY: 100
  MAX_SIZE: null
  ORIGINAL_RESOLUTION: true
  SCALE: false
  SCALE_FACTOR: 1.0
  VIEWS_GENERATION_APPROACH: null
  VIEWS_REDUCTION_APPROACH: mean
  WEBP_COMPRESSION: false
  WEBP_QUALITY: 100
THROUGHPUT_MODE: false
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: true
  BASE_LR: 0.0005
  CLIP_GRAD: null
  EPOCHS: 35
  LAYER_DECAY: 0.8
  LOSS: bce
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    GAMMA: 0.1
    MULTISTEPS: []
    NAME: cosine
  MIN_LR: 2.5e-07
  MODE: supervised
  OPTIMIZER:
    BETAS:
    - 0.9
    - 0.999
    EPS: 1.0e-08
    MOMENTUM: 0.9
    NAME: adamw
  SCALE_LR: false
  START_EPOCH: 0
  TRIPLET_LOSS_MARGIN: 0.5
  USE_CHECKPOINT: false
  WARMUP_EPOCHS: 5
  WARMUP_LR: 2.5e-07
  WEIGHT_DECAY: 0.05

[2025-05-08 10:13:46 finetune](data_finetune.py 482): INFO Data transform | mode: supervised | split: train:
Compose([
  RandomResizedCrop(p=1.0, size=(224, 224), scale=(0.2, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=1),
  HorizontalFlip(p=0.5),
  VerticalFlip(p=0.5),
  Rotate(p=0.5, limit=(-90, 90), interpolation=1, border_mode=4, value=None, mask_value=None, rotate_method='largest_box', crop_border=True),
  Resize(p=1.0, height=224, width=224, interpolation=1),
  GaussianBlur(p=0.5, blur_limit=(3, 9), sigma_limit=(0.01, 0.5)),
  GaussNoise(p=0.5, var_limit=(10.0, 50.0), per_channel=True, mean=0.0, noise_scale_factor=1.0),
  ColorJitter(p=0.0, brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=(0.8, 1.2), hue=(-0.1, 0.1)),
  Sharpen(p=0.0, alpha=(0.01, 0.4), lightness=(0.95, 1.0)),
  ImageCompression(p=0.5, quality_range=(50, 100), compression_type=0),
  ImageCompression(p=0.0, quality_range=(50, 100), compression_type=1),
  Normalize(p=1.0, mean=0.0, std=1.0, max_pixel_value=255.0, normalization='standard'),
  ToTensorV2(p=1.0, transpose_mask=False),
], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={}, is_check_shapes=True)
[2025-05-08 10:13:46 finetune](data_finetune.py 482): INFO Data transform | mode: supervised | split: val:
Compose([
  ImageCompression(p=0.0, quality_range=(100, 100), compression_type=0),
  ImageCompression(p=0.0, quality_range=(100, 100), compression_type=1),
  GaussianBlur(p=0.0, blur_limit=(3, 3), sigma_limit=(0, 0)),
  GaussNoise(p=0.0, var_limit=(1.0, 1.0), per_channel=True, mean=0.0, noise_scale_factor=1.0),
  RandomScale(p=0.0, interpolation=1, scale_limit=(0.0, 0.0)),
  PadIfNeeded(p=1.0, min_height=224, min_width=224, pad_height_divisor=None, pad_width_divisor=None, position=PositionType.CENTER, border_mode=4, value=None, mask_value=None),
  Normalize(p=1.0, mean=0.0, std=1.0, max_pixel_value=255.0, normalization='standard'),
  ToTensorV2(p=1.0, transpose_mask=False),
], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={}, is_check_shapes=True)
[2025-05-08 10:13:47 finetune](data_finetune.py 343): INFO Train images: 27000 | Validation images: 3000
[2025-05-08 10:13:47 finetune](data_finetune.py 344): INFO Train Images Source: /home/pnair/spai/datasets
[2025-05-08 10:13:47 finetune](data_finetune.py 345): INFO Validation Images Source: /home/pnair/spai/datasets
[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/spai/beast-mode/e/BEAS-22
[2025-05-08 10:13:48 finetune](__main__.py 232): INFO Creating model:vit/finetune
LOADING ARBITRARY RESOLUTION MODEL: PatchBasedMFViT
[2025-05-08 10:13:51 finetune](__main__.py 235): INFO PatchBasedMFViT(
  (mfvit): MFViT(
    (vit): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
      )
      (pos_drop): Dropout(p=0.0, inplace=False)
      (blocks): ModuleList(
        (0): Block(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1-11): 11 x Block(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): Identity()
      (fc_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (cls_blocks): ModuleList(
        (0): Block(
          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=768, out_features=2304, bias=False)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (cls_norm): Identity()
      (intermediate_fc_norm): ModuleList(
        (0-11): 12 x LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      )
      (head): Linear(in_features=9216, out_features=2, bias=True)
    )
    (features_processor): FrequencyRestorationEstimator(
      (patch_projector): FeatureSpecificProjector(
        (projectors): ModuleList(
          (0-11): 12 x Projector(
            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (projector): Sequential(
              (0): Dropout(p=0.5, inplace=False)
              (1): Linear(in_features=768, out_features=1024, bias=True)
              (2): GELU(approximate='none')
              (3): Dropout(p=0.5, inplace=False)
              (4): Linear(in_features=1024, out_features=1024, bias=True)
              (5): Identity()
              (6): Dropout(p=0.5, inplace=False)
            )
            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (original_features_processor): FeatureImportanceProjector(
        (proj1): Projector(
          (norm1): Identity()
          (projector): Sequential(
            (0): Dropout(p=0.5, inplace=False)
            (1): Linear(in_features=2048, out_features=1024, bias=True)
            (2): GELU(approximate='none')
            (3): Dropout(p=0.5, inplace=False)
            (4): Linear(in_features=1024, out_features=1024, bias=True)
            (5): GELU(approximate='none')
            (6): Dropout(p=0.5, inplace=False)
          )
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        )
        (proj2): Projector(
          (norm1): Identity()
          (projector): Sequential(
            (0): Dropout(p=0.5, inplace=False)
            (1): Linear(in_features=1024, out_features=1024, bias=True)
            (2): GELU(approximate='none')
            (3): Dropout(p=0.5, inplace=False)
            (4): Linear(in_features=1024, out_features=1024, bias=True)
            (5): GELU(approximate='none')
            (6): Dropout(p=0.5, inplace=False)
          )
          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (backbone_norm): Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
  )
  (attend): Softmax(dim=-1)
  (dropout): Dropout(p=0.5, inplace=False)
  (to_kv): Linear(in_features=1096, out_features=3072, bias=False)
  (to_out): Sequential(
    (0): Linear(in_features=1536, out_features=1096, bias=False)
    (1): Dropout(p=0.5, inplace=False)
  )
  (norm): LayerNorm((1096,), eps=1e-05, elementwise_affine=True)
  (cls_head): ClassificationHead(
    (head): Sequential(
      (0): Linear(in_features=1096, out_features=3288, bias=True)
      (1): ReLU()
      (2): Dropout(p=0.5, inplace=False)
      (3): Linear(in_features=3288, out_features=3288, bias=True)
      (4): ReLU()
      (5): Dropout(p=0.5, inplace=False)
      (6): Linear(in_features=3288, out_features=1, bias=True)
    )
  )
)
[2025-05-08 10:13:51 finetune](optimizer.py 80): INFO >>>>>>>>>> Build Optimizer for Fine-tuning Stage
[2025-05-08 10:13:51 finetune](optimizer.py 192): INFO Param groups = {
  "layer_13_decay": {
    "group_name": "layer_13_decay",
    "weight_decay": 0.05,
    "params": [
      "patch_aggregator",
      "mfvit.vit.cls_token",
      "mfvit.vit.pos_embed",
      "mfvit.vit.cls_pos_embed",
      "mfvit.vit.actual_cls_token",
      "mfvit.vit.patch_embed.proj.weight",
      "mfvit.vit.blocks.0.attn.qkv.weight",
      "mfvit.vit.blocks.0.attn.proj.weight",
      "mfvit.vit.blocks.0.mlp.fc1.weight",
      "mfvit.vit.blocks.0.mlp.fc2.weight",
      "mfvit.vit.blocks.1.attn.qkv.weight",
      "mfvit.vit.blocks.1.attn.proj.weight",
      "mfvit.vit.blocks.1.mlp.fc1.weight",
      "mfvit.vit.blocks.1.mlp.fc2.weight",
      "mfvit.vit.blocks.2.attn.qkv.weight",
      "mfvit.vit.blocks.2.attn.proj.weight",
      "mfvit.vit.blocks.2.mlp.fc1.weight",
      "mfvit.vit.blocks.2.mlp.fc2.weight",
      "mfvit.vit.blocks.3.attn.qkv.weight",
      "mfvit.vit.blocks.3.attn.proj.weight",
      "mfvit.vit.blocks.3.mlp.fc1.weight",
      "mfvit.vit.blocks.3.mlp.fc2.weight",
      "mfvit.vit.blocks.4.attn.qkv.weight",
      "mfvit.vit.blocks.4.attn.proj.weight",
      "mfvit.vit.blocks.4.mlp.fc1.weight",
      "mfvit.vit.blocks.4.mlp.fc2.weight",
      "mfvit.vit.blocks.5.attn.qkv.weight",
      "mfvit.vit.blocks.5.attn.proj.weight",
      "mfvit.vit.blocks.5.mlp.fc1.weight",
      "mfvit.vit.blocks.5.mlp.fc2.weight",
      "mfvit.vit.blocks.6.attn.qkv.weight",
      "mfvit.vit.blocks.6.attn.proj.weight",
      "mfvit.vit.blocks.6.mlp.fc1.weight",
      "mfvit.vit.blocks.6.mlp.fc2.weight",
      "mfvit.vit.blocks.7.attn.qkv.weight",
      "mfvit.vit.blocks.7.attn.proj.weight",
      "mfvit.vit.blocks.7.mlp.fc1.weight",
      "mfvit.vit.blocks.7.mlp.fc2.weight",
      "mfvit.vit.blocks.8.attn.qkv.weight",
      "mfvit.vit.blocks.8.attn.proj.weight",
      "mfvit.vit.blocks.8.mlp.fc1.weight",
      "mfvit.vit.blocks.8.mlp.fc2.weight",
      "mfvit.vit.blocks.9.attn.qkv.weight",
      "mfvit.vit.blocks.9.attn.proj.weight",
      "mfvit.vit.blocks.9.mlp.fc1.weight",
      "mfvit.vit.blocks.9.mlp.fc2.weight",
      "mfvit.vit.blocks.10.attn.qkv.weight",
      "mfvit.vit.blocks.10.attn.proj.weight",
      "mfvit.vit.blocks.10.mlp.fc1.weight",
      "mfvit.vit.blocks.10.mlp.fc2.weight",
      "mfvit.vit.blocks.11.attn.qkv.weight",
      "mfvit.vit.blocks.11.attn.proj.weight",
      "mfvit.vit.blocks.11.mlp.fc1.weight",
      "mfvit.vit.blocks.11.mlp.fc2.weight",
      "mfvit.vit.cls_blocks.0.attn.qkv.weight",
      "mfvit.vit.cls_blocks.0.attn.proj.weight",
      "mfvit.vit.cls_blocks.0.mlp.fc1.weight",
      "mfvit.vit.cls_blocks.0.mlp.fc2.weight",
      "mfvit.vit.head.weight",
      "mfvit.features_processor.patch_projector.projectors.0.projector.1.weight",
      "mfvit.features_processor.patch_projector.projectors.0.projector.4.weight",
      "mfvit.features_processor.patch_projector.projectors.1.projector.1.weight",
      "mfvit.features_processor.patch_projector.projectors.1.projector.4.weight",
      "mfvit.features_processor.patch_projector.projectors.2.projector.1.weight",
      "mfvit.features_processor.patch_projector.projectors.2.projector.4.weight",
      "mfvit.features_processor.patch_projector.projectors.3.projector.1.weight",
      "mfvit.features_processor.patch_projector.projectors.3.projector.4.weight",
      "mfvit.features_processor.patch_projector.projectors.4.projector.1.weight",
      "mfvit.features_processor.patch_projector.projectors.4.projector.4.weight",
      "mfvit.features_processor.patch_projector.projectors.5.projector.1.weight",
      "mfvit.features_processor.patch_projector.projectors.5.projector.4.weight",
      "mfvit.features_processor.patch_projector.projectors.6.projector.1.weight",
      "mfvit.features_processor.patch_projector.projectors.6.projector.4.weight",
      "mfvit.features_processor.patch_projector.projectors.7.projector.1.weight",
      "mfvit.features_processor.patch_projector.projectors.7.projector.4.weight",
      "mfvit.features_processor.patch_projector.projectors.8.projector.1.weight",
      "mfvit.features_processor.patch_projector.projectors.8.projector.4.weight",
      "mfvit.features_processor.patch_projector.projectors.9.projector.1.weight",
      "mfvit.features_processor.patch_projector.projectors.9.projector.4.weight",
      "mfvit.features_processor.patch_projector.projectors.10.projector.1.weight",
      "mfvit.features_processor.patch_projector.projectors.10.projector.4.weight",
      "mfvit.features_processor.patch_projector.projectors.11.projector.1.weight",
      "mfvit.features_processor.patch_projector.projectors.11.projector.4.weight",
      "mfvit.features_processor.original_features_processor.alpha",
      "mfvit.features_processor.original_features_processor.proj1.projector.1.weight",
      "mfvit.features_processor.original_features_processor.proj1.projector.4.weight",
      "mfvit.features_processor.original_features_processor.proj2.projector.1.weight",
      "mfvit.features_processor.original_features_processor.proj2.projector.4.weight",
      "to_kv.weight",
      "to_out.0.weight",
      "cls_head.head.0.weight",
      "cls_head.head.3.weight",
      "cls_head.head.6.weight"
    ],
    "lr": 0.0005,
    "lr_scale": 1.0
  },
  "layer_13_no_decay": {
    "group_name": "layer_13_no_decay",
    "weight_decay": 0.0,
    "params": [
      "mfvit.vit.patch_embed.proj.bias",
      "mfvit.vit.blocks.0.norm1.weight",
      "mfvit.vit.blocks.0.norm1.bias",
      "mfvit.vit.blocks.0.attn.q_bias",
      "mfvit.vit.blocks.0.attn.v_bias",
      "mfvit.vit.blocks.0.attn.proj.bias",
      "mfvit.vit.blocks.0.norm2.weight",
      "mfvit.vit.blocks.0.norm2.bias",
      "mfvit.vit.blocks.0.mlp.fc1.bias",
      "mfvit.vit.blocks.0.mlp.fc2.bias",
      "mfvit.vit.blocks.1.norm1.weight",
      "mfvit.vit.blocks.1.norm1.bias",
      "mfvit.vit.blocks.1.attn.q_bias",
      "mfvit.vit.blocks.1.attn.v_bias",
      "mfvit.vit.blocks.1.attn.proj.bias",
      "mfvit.vit.blocks.1.norm2.weight",
      "mfvit.vit.blocks.1.norm2.bias",
      "mfvit.vit.blocks.1.mlp.fc1.bias",
      "mfvit.vit.blocks.1.mlp.fc2.bias",
      "mfvit.vit.blocks.2.norm1.weight",
      "mfvit.vit.blocks.2.norm1.bias",
      "mfvit.vit.blocks.2.attn.q_bias",
      "mfvit.vit.blocks.2.attn.v_bias",
      "mfvit.vit.blocks.2.attn.proj.bias",
      "mfvit.vit.blocks.2.norm2.weight",
      "mfvit.vit.blocks.2.norm2.bias",
      "mfvit.vit.blocks.2.mlp.fc1.bias",
      "mfvit.vit.blocks.2.mlp.fc2.bias",
      "mfvit.vit.blocks.3.norm1.weight",
      "mfvit.vit.blocks.3.norm1.bias",
      "mfvit.vit.blocks.3.attn.q_bias",
      "mfvit.vit.blocks.3.attn.v_bias",
      "mfvit.vit.blocks.3.attn.proj.bias",
      "mfvit.vit.blocks.3.norm2.weight",
      "mfvit.vit.blocks.3.norm2.bias",
      "mfvit.vit.blocks.3.mlp.fc1.bias",
      "mfvit.vit.blocks.3.mlp.fc2.bias",
      "mfvit.vit.blocks.4.norm1.weight",
      "mfvit.vit.blocks.4.norm1.bias",
      "mfvit.vit.blocks.4.attn.q_bias",
      "mfvit.vit.blocks.4.attn.v_bias",
      "mfvit.vit.blocks.4.attn.proj.bias",
      "mfvit.vit.blocks.4.norm2.weight",
      "mfvit.vit.blocks.4.norm2.bias",
      "mfvit.vit.blocks.4.mlp.fc1.bias",
      "mfvit.vit.blocks.4.mlp.fc2.bias",
      "mfvit.vit.blocks.5.norm1.weight",
      "mfvit.vit.blocks.5.norm1.bias",
      "mfvit.vit.blocks.5.attn.q_bias",
      "mfvit.vit.blocks.5.attn.v_bias",
      "mfvit.vit.blocks.5.attn.proj.bias",
      "mfvit.vit.blocks.5.norm2.weight",
      "mfvit.vit.blocks.5.norm2.bias",
      "mfvit.vit.blocks.5.mlp.fc1.bias",
      "mfvit.vit.blocks.5.mlp.fc2.bias",
      "mfvit.vit.blocks.6.norm1.weight",
      "mfvit.vit.blocks.6.norm1.bias",
      "mfvit.vit.blocks.6.attn.q_bias",
      "mfvit.vit.blocks.6.attn.v_bias",
      "mfvit.vit.blocks.6.attn.proj.bias",
      "mfvit.vit.blocks.6.norm2.weight",
      "mfvit.vit.blocks.6.norm2.bias",
      "mfvit.vit.blocks.6.mlp.fc1.bias",
      "mfvit.vit.blocks.6.mlp.fc2.bias",
      "mfvit.vit.blocks.7.norm1.weight",
      "mfvit.vit.blocks.7.norm1.bias",
      "mfvit.vit.blocks.7.attn.q_bias",
      "mfvit.vit.blocks.7.attn.v_bias",
      "mfvit.vit.blocks.7.attn.proj.bias",
      "mfvit.vit.blocks.7.norm2.weight",
      "mfvit.vit.blocks.7.norm2.bias",
      "mfvit.vit.blocks.7.mlp.fc1.bias",
      "mfvit.vit.blocks.7.mlp.fc2.bias",
      "mfvit.vit.blocks.8.norm1.weight",
      "mfvit.vit.blocks.8.norm1.bias",
      "mfvit.vit.blocks.8.attn.q_bias",
      "mfvit.vit.blocks.8.attn.v_bias",
      "mfvit.vit.blocks.8.attn.proj.bias",
      "mfvit.vit.blocks.8.norm2.weight",
      "mfvit.vit.blocks.8.norm2.bias",
      "mfvit.vit.blocks.8.mlp.fc1.bias",
      "mfvit.vit.blocks.8.mlp.fc2.bias",
      "mfvit.vit.blocks.9.norm1.weight",
      "mfvit.vit.blocks.9.norm1.bias",
      "mfvit.vit.blocks.9.attn.q_bias",
      "mfvit.vit.blocks.9.attn.v_bias",
      "mfvit.vit.blocks.9.attn.proj.bias",
      "mfvit.vit.blocks.9.norm2.weight",
      "mfvit.vit.blocks.9.norm2.bias",
      "mfvit.vit.blocks.9.mlp.fc1.bias",
      "mfvit.vit.blocks.9.mlp.fc2.bias",
      "mfvit.vit.blocks.10.norm1.weight",
      "mfvit.vit.blocks.10.norm1.bias",
      "mfvit.vit.blocks.10.attn.q_bias",
      "mfvit.vit.blocks.10.attn.v_bias",
      "mfvit.vit.blocks.10.attn.proj.bias",
      "mfvit.vit.blocks.10.norm2.weight",
      "mfvit.vit.blocks.10.norm2.bias",
      "mfvit.vit.blocks.10.mlp.fc1.bias",
      "mfvit.vit.blocks.10.mlp.fc2.bias",
      "mfvit.vit.blocks.11.norm1.weight",
      "mfvit.vit.blocks.11.norm1.bias",
      "mfvit.vit.blocks.11.attn.q_bias",
      "mfvit.vit.blocks.11.attn.v_bias",
      "mfvit.vit.blocks.11.attn.proj.bias",
      "mfvit.vit.blocks.11.norm2.weight",
      "mfvit.vit.blocks.11.norm2.bias",
      "mfvit.vit.blocks.11.mlp.fc1.bias",
      "mfvit.vit.blocks.11.mlp.fc2.bias",
      "mfvit.vit.fc_norm.weight",
      "mfvit.vit.fc_norm.bias",
      "mfvit.vit.cls_blocks.0.norm1.weight",
      "mfvit.vit.cls_blocks.0.norm1.bias",
      "mfvit.vit.cls_blocks.0.attn.q_bias",
      "mfvit.vit.cls_blocks.0.attn.v_bias",
      "mfvit.vit.cls_blocks.0.attn.proj.bias",
      "mfvit.vit.cls_blocks.0.norm2.weight",
      "mfvit.vit.cls_blocks.0.norm2.bias",
      "mfvit.vit.cls_blocks.0.mlp.fc1.bias",
      "mfvit.vit.cls_blocks.0.mlp.fc2.bias",
      "mfvit.vit.intermediate_fc_norm.0.weight",
      "mfvit.vit.intermediate_fc_norm.0.bias",
      "mfvit.vit.intermediate_fc_norm.1.weight",
      "mfvit.vit.intermediate_fc_norm.1.bias",
      "mfvit.vit.intermediate_fc_norm.2.weight",
      "mfvit.vit.intermediate_fc_norm.2.bias",
      "mfvit.vit.intermediate_fc_norm.3.weight",
      "mfvit.vit.intermediate_fc_norm.3.bias",
      "mfvit.vit.intermediate_fc_norm.4.weight",
      "mfvit.vit.intermediate_fc_norm.4.bias",
      "mfvit.vit.intermediate_fc_norm.5.weight",
      "mfvit.vit.intermediate_fc_norm.5.bias",
      "mfvit.vit.intermediate_fc_norm.6.weight",
      "mfvit.vit.intermediate_fc_norm.6.bias",
      "mfvit.vit.intermediate_fc_norm.7.weight",
      "mfvit.vit.intermediate_fc_norm.7.bias",
      "mfvit.vit.intermediate_fc_norm.8.weight",
      "mfvit.vit.intermediate_fc_norm.8.bias",
      "mfvit.vit.intermediate_fc_norm.9.weight",
      "mfvit.vit.intermediate_fc_norm.9.bias",
      "mfvit.vit.intermediate_fc_norm.10.weight",
      "mfvit.vit.intermediate_fc_norm.10.bias",
      "mfvit.vit.intermediate_fc_norm.11.weight",
      "mfvit.vit.intermediate_fc_norm.11.bias",
      "mfvit.vit.head.bias",
      "mfvit.features_processor.patch_projector.projectors.0.norm1.weight",
      "mfvit.features_processor.patch_projector.projectors.0.norm1.bias",
      "mfvit.features_processor.patch_projector.projectors.0.projector.1.bias",
      "mfvit.features_processor.patch_projector.projectors.0.projector.4.bias",
      "mfvit.features_processor.patch_projector.projectors.0.norm2.weight",
      "mfvit.features_processor.patch_projector.projectors.0.norm2.bias",
      "mfvit.features_processor.patch_projector.projectors.1.norm1.weight",
      "mfvit.features_processor.patch_projector.projectors.1.norm1.bias",
      "mfvit.features_processor.patch_projector.projectors.1.projector.1.bias",
      "mfvit.features_processor.patch_projector.projectors.1.projector.4.bias",
      "mfvit.features_processor.patch_projector.projectors.1.norm2.weight",
      "mfvit.features_processor.patch_projector.projectors.1.norm2.bias",
      "mfvit.features_processor.patch_projector.projectors.2.norm1.weight",
      "mfvit.features_processor.patch_projector.projectors.2.norm1.bias",
      "mfvit.features_processor.patch_projector.projectors.2.projector.1.bias",
      "mfvit.features_processor.patch_projector.projectors.2.projector.4.bias",
      "mfvit.features_processor.patch_projector.projectors.2.norm2.weight",
      "mfvit.features_processor.patch_projector.projectors.2.norm2.bias",
      "mfvit.features_processor.patch_projector.projectors.3.norm1.weight",
      "mfvit.features_processor.patch_projector.projectors.3.norm1.bias",
      "mfvit.features_processor.patch_projector.projectors.3.projector.1.bias",
      "mfvit.features_processor.patch_projector.projectors.3.projector.4.bias",
      "mfvit.features_processor.patch_projector.projectors.3.norm2.weight",
      "mfvit.features_processor.patch_projector.projectors.3.norm2.bias",
      "mfvit.features_processor.patch_projector.projectors.4.norm1.weight",
      "mfvit.features_processor.patch_projector.projectors.4.norm1.bias",
      "mfvit.features_processor.patch_projector.projectors.4.projector.1.bias",
      "mfvit.features_processor.patch_projector.projectors.4.projector.4.bias",
      "mfvit.features_processor.patch_projector.projectors.4.norm2.weight",
      "mfvit.features_processor.patch_projector.projectors.4.norm2.bias",
      "mfvit.features_processor.patch_projector.projectors.5.norm1.weight",
      "mfvit.features_processor.patch_projector.projectors.5.norm1.bias",
      "mfvit.features_processor.patch_projector.projectors.5.projector.1.bias",
      "mfvit.features_processor.patch_projector.projectors.5.projector.4.bias",
      "mfvit.features_processor.patch_projector.projectors.5.norm2.weight",
      "mfvit.features_processor.patch_projector.projectors.5.norm2.bias",
      "mfvit.features_processor.patch_projector.projectors.6.norm1.weight",
      "mfvit.features_processor.patch_projector.projectors.6.norm1.bias",
      "mfvit.features_processor.patch_projector.projectors.6.projector.1.bias",
      "mfvit.features_processor.patch_projector.projectors.6.projector.4.bias",
      "mfvit.features_processor.patch_projector.projectors.6.norm2.weight",
      "mfvit.features_processor.patch_projector.projectors.6.norm2.bias",
      "mfvit.features_processor.patch_projector.projectors.7.norm1.weight",
      "mfvit.features_processor.patch_projector.projectors.7.norm1.bias",
      "mfvit.features_processor.patch_projector.projectors.7.projector.1.bias",
      "mfvit.features_processor.patch_projector.projectors.7.projector.4.bias",
      "mfvit.features_processor.patch_projector.projectors.7.norm2.weight",
      "mfvit.features_processor.patch_projector.projectors.7.norm2.bias",
      "mfvit.features_processor.patch_projector.projectors.8.norm1.weight",
      "mfvit.features_processor.patch_projector.projectors.8.norm1.bias",
      "mfvit.features_processor.patch_projector.projectors.8.projector.1.bias",
      "mfvit.features_processor.patch_projector.projectors.8.projector.4.bias",
      "mfvit.features_processor.patch_projector.projectors.8.norm2.weight",
      "mfvit.features_processor.patch_projector.projectors.8.norm2.bias",
      "mfvit.features_processor.patch_projector.projectors.9.norm1.weight",
      "mfvit.features_processor.patch_projector.projectors.9.norm1.bias",
      "mfvit.features_processor.patch_projector.projectors.9.projector.1.bias",
      "mfvit.features_processor.patch_projector.projectors.9.projector.4.bias",
      "mfvit.features_processor.patch_projector.projectors.9.norm2.weight",
      "mfvit.features_processor.patch_projector.projectors.9.norm2.bias",
      "mfvit.features_processor.patch_projector.projectors.10.norm1.weight",
      "mfvit.features_processor.patch_projector.projectors.10.norm1.bias",
      "mfvit.features_processor.patch_projector.projectors.10.projector.1.bias",
      "mfvit.features_processor.patch_projector.projectors.10.projector.4.bias",
      "mfvit.features_processor.patch_projector.projectors.10.norm2.weight",
      "mfvit.features_processor.patch_projector.projectors.10.norm2.bias",
      "mfvit.features_processor.patch_projector.projectors.11.norm1.weight",
      "mfvit.features_processor.patch_projector.projectors.11.norm1.bias",
      "mfvit.features_processor.patch_projector.projectors.11.projector.1.bias",
      "mfvit.features_processor.patch_projector.projectors.11.projector.4.bias",
      "mfvit.features_processor.patch_projector.projectors.11.norm2.weight",
      "mfvit.features_processor.patch_projector.projectors.11.norm2.bias",
      "mfvit.features_processor.original_features_processor.proj1.projector.1.bias",
      "mfvit.features_processor.original_features_processor.proj1.projector.4.bias",
      "mfvit.features_processor.original_features_processor.proj1.norm2.weight",
      "mfvit.features_processor.original_features_processor.proj1.norm2.bias",
      "mfvit.features_processor.original_features_processor.proj2.projector.1.bias",
      "mfvit.features_processor.original_features_processor.proj2.projector.4.bias",
      "mfvit.features_processor.original_features_processor.proj2.norm2.weight",
      "mfvit.features_processor.original_features_processor.proj2.norm2.bias",
      "norm.weight",
      "norm.bias",
      "cls_head.head.0.bias",
      "cls_head.head.3.bias",
      "cls_head.head.6.bias"
    ],
    "lr": 0.0005,
    "lr_scale": 1.0
  }
}
[2025-05-08 10:13:51 finetune](optimizer.py 115): INFO AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    group_name: layer_13_decay
    lr: 0.0005
    lr_scale: 1.0
    maximize: False
    weight_decay: 0.05

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    group_name: layer_13_no_decay
    lr: 0.0005
    lr_scale: 1.0
    maximize: False
    weight_decay: 0.0
)
/home/pnair/.conda/envs/spai/lib/python3.11/site-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
  warnings.warn(msg, DeprecatedFeatureWarning)
/home/pnair/.conda/envs/spai/lib/python3.11/site-packages/apex/amp/scaler.py:56: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  self._overflow_buf = torch.cuda.IntTensor([0])
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError("No module named 'amp_C'")
[2025-05-08 10:13:51 finetune](__main__.py 251): INFO number of params: 14424457
[2025-05-08 10:13:51 finetune](__main__.py 258): INFO Loss: 
BCEWithLogitsLoss()
[2025-05-08 10:13:51 finetune](utils.py 146): INFO >>>>>>>>>> Fine-tuned from /home/pnair/spai/weights/mfm_pretrain_vit_base.pth ..........
[2025-05-08 10:13:51 finetune](utils.py 160): INFO Detect non-pre-trained model, pass without doing anything.
[2025-05-08 10:13:51 finetune](utils.py 166): INFO >>>>>>>>>> Remapping pre-trained keys for VIT ..........
key: cls_token
key: pos_embed
key: patch_embed.proj.weight
key: patch_embed.proj.bias
key: blocks.0.norm1.weight
key: blocks.0.norm1.bias
key: blocks.0.attn.q_bias
key: blocks.0.attn.v_bias
key: blocks.0.attn.qkv.weight
key: blocks.0.attn.proj.weight
key: blocks.0.attn.proj.bias
key: blocks.0.norm2.weight
key: blocks.0.norm2.bias
key: blocks.0.mlp.fc1.weight
key: blocks.0.mlp.fc1.bias
key: blocks.0.mlp.fc2.weight
key: blocks.0.mlp.fc2.bias
key: blocks.1.norm1.weight
key: blocks.1.norm1.bias
key: blocks.1.attn.q_bias
key: blocks.1.attn.v_bias
key: blocks.1.attn.qkv.weight
key: blocks.1.attn.proj.weight
key: blocks.1.attn.proj.bias
key: blocks.1.norm2.weight
key: blocks.1.norm2.bias
key: blocks.1.mlp.fc1.weight
key: blocks.1.mlp.fc1.bias
key: blocks.1.mlp.fc2.weight
key: blocks.1.mlp.fc2.bias
key: blocks.2.norm1.weight
key: blocks.2.norm1.bias
key: blocks.2.attn.q_bias
key: blocks.2.attn.v_bias
key: blocks.2.attn.qkv.weight
key: blocks.2.attn.proj.weight
key: blocks.2.attn.proj.bias
key: blocks.2.norm2.weight
key: blocks.2.norm2.bias
key: blocks.2.mlp.fc1.weight
key: blocks.2.mlp.fc1.bias
key: blocks.2.mlp.fc2.weight
key: blocks.2.mlp.fc2.bias
key: blocks.3.norm1.weight
key: blocks.3.norm1.bias
key: blocks.3.attn.q_bias
key: blocks.3.attn.v_bias
key: blocks.3.attn.qkv.weight
key: blocks.3.attn.proj.weight
key: blocks.3.attn.proj.bias
key: blocks.3.norm2.weight
key: blocks.3.norm2.bias
key: blocks.3.mlp.fc1.weight
key: blocks.3.mlp.fc1.bias
key: blocks.3.mlp.fc2.weight
key: blocks.3.mlp.fc2.bias
key: blocks.4.norm1.weight
key: blocks.4.norm1.bias
key: blocks.4.attn.q_bias
key: blocks.4.attn.v_bias
key: blocks.4.attn.qkv.weight
key: blocks.4.attn.proj.weight
key: blocks.4.attn.proj.bias
key: blocks.4.norm2.weight
key: blocks.4.norm2.bias
key: blocks.4.mlp.fc1.weight
key: blocks.4.mlp.fc1.bias
key: blocks.4.mlp.fc2.weight
key: blocks.4.mlp.fc2.bias
key: blocks.5.norm1.weight
key: blocks.5.norm1.bias
key: blocks.5.attn.q_bias
key: blocks.5.attn.v_bias
key: blocks.5.attn.qkv.weight
key: blocks.5.attn.proj.weight
key: blocks.5.attn.proj.bias
key: blocks.5.norm2.weight
key: blocks.5.norm2.bias
key: blocks.5.mlp.fc1.weight
key: blocks.5.mlp.fc1.bias
key: blocks.5.mlp.fc2.weight
key: blocks.5.mlp.fc2.bias
key: blocks.6.norm1.weight
key: blocks.6.norm1.bias
key: blocks.6.attn.q_bias
key: blocks.6.attn.v_bias
key: blocks.6.attn.qkv.weight
key: blocks.6.attn.proj.weight
key: blocks.6.attn.proj.bias
key: blocks.6.norm2.weight
key: blocks.6.norm2.bias
key: blocks.6.mlp.fc1.weight
key: blocks.6.mlp.fc1.bias
key: blocks.6.mlp.fc2.weight
key: blocks.6.mlp.fc2.bias
key: blocks.7.norm1.weight
key: blocks.7.norm1.bias
key: blocks.7.attn.q_bias
key: blocks.7.attn.v_bias
key: blocks.7.attn.qkv.weight
key: blocks.7.attn.proj.weight
key: blocks.7.attn.proj.bias
key: blocks.7.norm2.weight
key: blocks.7.norm2.bias
key: blocks.7.mlp.fc1.weight
key: blocks.7.mlp.fc1.bias
key: blocks.7.mlp.fc2.weight
key: blocks.7.mlp.fc2.bias
key: blocks.8.norm1.weight
key: blocks.8.norm1.bias
key: blocks.8.attn.q_bias
key: blocks.8.attn.v_bias
key: blocks.8.attn.qkv.weight
key: blocks.8.attn.proj.weight
key: blocks.8.attn.proj.bias
key: blocks.8.norm2.weight
key: blocks.8.norm2.bias
key: blocks.8.mlp.fc1.weight
key: blocks.8.mlp.fc1.bias
key: blocks.8.mlp.fc2.weight
key: blocks.8.mlp.fc2.bias
key: blocks.9.norm1.weight
key: blocks.9.norm1.bias
key: blocks.9.attn.q_bias
key: blocks.9.attn.v_bias
key: blocks.9.attn.qkv.weight
key: blocks.9.attn.proj.weight
key: blocks.9.attn.proj.bias
key: blocks.9.norm2.weight
key: blocks.9.norm2.bias
key: blocks.9.mlp.fc1.weight
key: blocks.9.mlp.fc1.bias
key: blocks.9.mlp.fc2.weight
key: blocks.9.mlp.fc2.bias
key: blocks.10.norm1.weight
key: blocks.10.norm1.bias
key: blocks.10.attn.q_bias
key: blocks.10.attn.v_bias
key: blocks.10.attn.qkv.weight
key: blocks.10.attn.proj.weight
key: blocks.10.attn.proj.bias
key: blocks.10.norm2.weight
key: blocks.10.norm2.bias
key: blocks.10.mlp.fc1.weight
key: blocks.10.mlp.fc1.bias
key: blocks.10.mlp.fc2.weight
key: blocks.10.mlp.fc2.bias
key: blocks.11.norm1.weight
key: blocks.11.norm1.bias
key: blocks.11.attn.q_bias
key: blocks.11.attn.v_bias
key: blocks.11.attn.qkv.weight
key: blocks.11.attn.proj.weight
key: blocks.11.attn.proj.bias
key: blocks.11.norm2.weight
key: blocks.11.norm2.bias
key: blocks.11.mlp.fc1.weight
key: blocks.11.mlp.fc1.bias
key: blocks.11.mlp.fc2.weight
key: blocks.11.mlp.fc2.bias
key: norm.weight
key: norm.bias
[2025-05-08 10:13:51 finetune](utils.py 173): INFO _IncompatibleKeys(missing_keys=['cls_pos_embed', 'actual_cls_token', 'fc_norm.weight', 'fc_norm.bias', 'cls_blocks.0.norm1.weight', 'cls_blocks.0.norm1.bias', 'cls_blocks.0.attn.q_bias', 'cls_blocks.0.attn.v_bias', 'cls_blocks.0.attn.qkv.weight', 'cls_blocks.0.attn.proj.weight', 'cls_blocks.0.attn.proj.bias', 'cls_blocks.0.norm2.weight', 'cls_blocks.0.norm2.bias', 'cls_blocks.0.mlp.fc1.weight', 'cls_blocks.0.mlp.fc1.bias', 'cls_blocks.0.mlp.fc2.weight', 'cls_blocks.0.mlp.fc2.bias', 'intermediate_fc_norm.0.weight', 'intermediate_fc_norm.0.bias', 'intermediate_fc_norm.1.weight', 'intermediate_fc_norm.1.bias', 'intermediate_fc_norm.2.weight', 'intermediate_fc_norm.2.bias', 'intermediate_fc_norm.3.weight', 'intermediate_fc_norm.3.bias', 'intermediate_fc_norm.4.weight', 'intermediate_fc_norm.4.bias', 'intermediate_fc_norm.5.weight', 'intermediate_fc_norm.5.bias', 'intermediate_fc_norm.6.weight', 'intermediate_fc_norm.6.bias', 'intermediate_fc_norm.7.weight', 'intermediate_fc_norm.7.bias', 'intermediate_fc_norm.8.weight', 'intermediate_fc_norm.8.bias', 'intermediate_fc_norm.9.weight', 'intermediate_fc_norm.9.bias', 'intermediate_fc_norm.10.weight', 'intermediate_fc_norm.10.bias', 'intermediate_fc_norm.11.weight', 'intermediate_fc_norm.11.bias', 'head.weight', 'head.bias'], unexpected_keys=['norm.weight', 'norm.bias'])
[2025-05-08 10:13:51 finetune](utils.py 178): INFO >>>>>>>>>> loaded successfully '/home/pnair/spai/weights/mfm_pretrain_vit_base.pth'
[2025-05-08 10:13:51 finetune](__main__.py 875): INFO Start training
[2025-05-08 10:13:51 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [2.5e-07, 2.5e-07]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:14:43 finetune](__main__.py 1101): INFO Train: [0/35][0/140]	eta 2:01:38 lr 0.000000	time 52.1340 (52.1340)	loss 0.8422 (0.8422)	grad_norm 4.7397 (4.7397)	mem 8539MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:20:39 finetune](__main__.py 1101): INFO Train: [0/35][100/140]	eta 0:02:41 lr 0.000072	time 0.6957 (4.0364)	loss 0.6965 (0.7058)	grad_norm 2.5778 (2.9869)	mem 8708MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:22:32 finetune](__main__.py 1110): INFO EPOCH 0 training takes 0:08:40
[2025-05-08 10:23:40 finetune](__main__.py 1196): INFO Test: [0/12] | Time 67.949 (67.949) | Loss 0.6672 (0.6672) | Mem 16673MB
[2025-05-08 10:23:52 finetune](__main__.py 906): INFO Val | Epoch 0 | Images: 3000 | loss: 0.6658
[2025-05-08 10:23:52 finetune](__main__.py 907): INFO Val | Epoch 0 | Images: 3000 | ACC: 0.670
[2025-05-08 10:23:52 finetune](__main__.py 908): INFO Val | Epoch 0 | Images: 3000 | AP: 0.690
[2025-05-08 10:23:52 finetune](__main__.py 909): INFO Val | Epoch 0 | Images: 3000 | AUC: 0.576
[2025-05-08 10:23:52 finetune](__main__.py 920): INFO Val | Min loss: 0.6658 | Epoch: 0
[2025-05-08 10:23:52 finetune](__main__.py 922): INFO Val | Max ACC: 0.670 | Epoch: 0
[2025-05-08 10:23:52 finetune](__main__.py 924): INFO Val | Max AP: 0.690 | Epoch: 0
[2025-05-08 10:23:52 finetune](__main__.py 926): INFO Val | Max AUC: 0.576 | Epoch: 0
[2025-05-08 10:23:52 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_0.pth saving......
[2025-05-08 10:23:53 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_0.pth saved !!!
[2025-05-08 10:23:53 finetune](__main__.py 955): INFO Epoch training time: 602.068s
[2025-05-08 10:23:54 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [9.948607142857143e-05, 9.948607142857143e-05]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:24:09 finetune](__main__.py 1101): INFO Train: [1/35][0/140]	eta 0:36:26 lr 0.000100	time 15.6183 (15.6183)	loss 0.6610 (0.6610)	grad_norm 2.9276 (2.9276)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:25:36 finetune](__main__.py 1101): INFO Train: [1/35][100/140]	eta 0:00:40 lr 0.000172	time 0.6951 (1.0165)	loss 0.7161 (0.6779)	grad_norm 2.0830 (2.2421)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:26:07 finetune](__main__.py 1110): INFO EPOCH 1 training takes 0:02:13
[2025-05-08 10:26:20 finetune](__main__.py 1196): INFO Test: [0/12] | Time 13.279 (13.279) | Loss 0.6353 (0.6353) | Mem 16698MB
[2025-05-08 10:26:32 finetune](__main__.py 906): INFO Val | Epoch 1 | Images: 3000 | loss: 0.6308
[2025-05-08 10:26:32 finetune](__main__.py 907): INFO Val | Epoch 1 | Images: 3000 | ACC: 0.671
[2025-05-08 10:26:32 finetune](__main__.py 908): INFO Val | Epoch 1 | Images: 3000 | AP: 0.794
[2025-05-08 10:26:32 finetune](__main__.py 909): INFO Val | Epoch 1 | Images: 3000 | AUC: 0.637
[2025-05-08 10:26:32 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 10:26:32 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 10:26:32 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 10:26:32 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 10:26:32 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_1.pth saving......
[2025-05-08 10:26:33 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_1.pth saved !!!
[2025-05-08 10:26:33 finetune](__main__.py 955): INFO Epoch training time: 159.696s
[2025-05-08 10:26:33 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [0.00019943607142857144, 0.00019943607142857144]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:26:45 finetune](__main__.py 1101): INFO Train: [2/35][0/140]	eta 0:26:34 lr 0.000200	time 11.3884 (11.3884)	loss 0.6300 (0.6300)	grad_norm 1.6905 (1.6905)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:28:16 finetune](__main__.py 1101): INFO Train: [2/35][100/140]	eta 0:00:40 lr 0.000272	time 0.6954 (1.0199)	loss 0.6650 (0.6612)	grad_norm 1.6351 (1.7177)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:28:53 finetune](__main__.py 1110): INFO EPOCH 2 training takes 0:02:19
[2025-05-08 10:29:11 finetune](__main__.py 1196): INFO Test: [0/12] | Time 18.039 (18.039) | Loss 0.6512 (0.6512) | Mem 16698MB
[2025-05-08 10:29:25 finetune](__main__.py 906): INFO Val | Epoch 2 | Images: 3000 | loss: 0.6479
[2025-05-08 10:29:25 finetune](__main__.py 907): INFO Val | Epoch 2 | Images: 3000 | ACC: 0.671
[2025-05-08 10:29:25 finetune](__main__.py 908): INFO Val | Epoch 2 | Images: 3000 | AP: 0.612
[2025-05-08 10:29:25 finetune](__main__.py 909): INFO Val | Epoch 2 | Images: 3000 | AUC: 0.413
[2025-05-08 10:29:25 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 10:29:25 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 10:29:25 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 10:29:25 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 10:29:25 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_2.pth saving......
[2025-05-08 10:29:26 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_2.pth saved !!!
[2025-05-08 10:29:26 finetune](__main__.py 955): INFO Epoch training time: 172.373s
[2025-05-08 10:29:26 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [0.0002993860714285714, 0.0002993860714285714]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:29:41 finetune](__main__.py 1101): INFO Train: [3/35][0/140]	eta 0:35:21 lr 0.000300	time 15.1560 (15.1560)	loss 0.6326 (0.6326)	grad_norm 1.2347 (1.2347)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:31:02 finetune](__main__.py 1101): INFO Train: [3/35][100/140]	eta 0:00:38 lr 0.000371	time 0.6953 (0.9528)	loss 0.6400 (0.6499)	grad_norm 1.0087 (1.2618)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:31:40 finetune](__main__.py 1110): INFO EPOCH 3 training takes 0:02:13
[2025-05-08 10:31:54 finetune](__main__.py 1196): INFO Test: [0/12] | Time 14.511 (14.511) | Loss 0.6433 (0.6433) | Mem 16698MB
[2025-05-08 10:32:05 finetune](__main__.py 906): INFO Val | Epoch 3 | Images: 3000 | loss: 0.6392
[2025-05-08 10:32:05 finetune](__main__.py 907): INFO Val | Epoch 3 | Images: 3000 | ACC: 0.671
[2025-05-08 10:32:05 finetune](__main__.py 908): INFO Val | Epoch 3 | Images: 3000 | AP: 0.634
[2025-05-08 10:32:05 finetune](__main__.py 909): INFO Val | Epoch 3 | Images: 3000 | AUC: 0.451
[2025-05-08 10:32:05 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 10:32:05 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 10:32:05 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 10:32:05 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 10:32:05 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_3.pth saving......
[2025-05-08 10:32:06 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_3.pth saved !!!
[2025-05-08 10:32:06 finetune](__main__.py 955): INFO Epoch training time: 159.910s
[2025-05-08 10:32:06 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [0.0003993360714285714, 0.0003993360714285714]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:32:25 finetune](__main__.py 1101): INFO Train: [4/35][0/140]	eta 0:44:04 lr 0.000400	time 18.8862 (18.8862)	loss 0.6371 (0.6371)	grad_norm 1.0471 (1.0471)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:33:53 finetune](__main__.py 1101): INFO Train: [4/35][100/140]	eta 0:00:42 lr 0.000471	time 0.6952 (1.0636)	loss 0.6625 (0.6479)	grad_norm 0.8605 (1.0167)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:34:25 finetune](__main__.py 1110): INFO EPOCH 4 training takes 0:02:19
[2025-05-08 10:34:36 finetune](__main__.py 1196): INFO Test: [0/12] | Time 10.725 (10.725) | Loss 0.6635 (0.6635) | Mem 16698MB
[2025-05-08 10:34:49 finetune](__main__.py 906): INFO Val | Epoch 4 | Images: 3000 | loss: 0.6561
[2025-05-08 10:34:49 finetune](__main__.py 907): INFO Val | Epoch 4 | Images: 3000 | ACC: 0.671
[2025-05-08 10:34:49 finetune](__main__.py 908): INFO Val | Epoch 4 | Images: 3000 | AP: 0.719
[2025-05-08 10:34:49 finetune](__main__.py 909): INFO Val | Epoch 4 | Images: 3000 | AUC: 0.554
[2025-05-08 10:34:49 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 10:34:49 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 10:34:49 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 10:34:49 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 10:34:49 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_4.pth saving......
[2025-05-08 10:34:49 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_4.pth saved !!!
[2025-05-08 10:34:49 finetune](__main__.py 955): INFO Epoch training time: 163.206s
[2025-05-08 10:34:49 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [0.0004992860714285714, 0.0004992860714285714]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:35:01 finetune](__main__.py 1101): INFO Train: [5/35][0/140]	eta 0:27:40 lr 0.000475	time 11.8639 (11.8639)	loss 0.6341 (0.6341)	grad_norm 0.9187 (0.9187)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:36:35 finetune](__main__.py 1101): INFO Train: [5/35][100/140]	eta 0:00:41 lr 0.000468	time 0.6953 (1.0469)	loss 0.6183 (0.6429)	grad_norm 0.8273 (0.8903)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:37:08 finetune](__main__.py 1110): INFO EPOCH 5 training takes 0:02:19
[2025-05-08 10:37:21 finetune](__main__.py 1196): INFO Test: [0/12] | Time 12.322 (12.322) | Loss 0.6379 (0.6379) | Mem 16698MB
[2025-05-08 10:37:32 finetune](__main__.py 906): INFO Val | Epoch 5 | Images: 3000 | loss: 0.6348
[2025-05-08 10:37:32 finetune](__main__.py 907): INFO Val | Epoch 5 | Images: 3000 | ACC: 0.671
[2025-05-08 10:37:32 finetune](__main__.py 908): INFO Val | Epoch 5 | Images: 3000 | AP: 0.730
[2025-05-08 10:37:32 finetune](__main__.py 909): INFO Val | Epoch 5 | Images: 3000 | AUC: 0.570
[2025-05-08 10:37:32 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 10:37:32 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 10:37:32 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 10:37:32 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 10:37:32 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_5.pth saving......
[2025-05-08 10:37:33 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_5.pth saved !!!
[2025-05-08 10:37:33 finetune](__main__.py 955): INFO Epoch training time: 163.520s
[2025-05-08 10:37:33 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [0.0004647120173378825, 0.0004647120173378825]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:37:49 finetune](__main__.py 1101): INFO Train: [6/35][0/140]	eta 0:37:42 lr 0.000465	time 16.1580 (16.1580)	loss 0.6307 (0.6307)	grad_norm 1.0666 (1.0666)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:39:08 finetune](__main__.py 1101): INFO Train: [6/35][100/140]	eta 0:00:37 lr 0.000456	time 0.6954 (0.9457)	loss 0.5985 (0.6445)	grad_norm 0.9896 (0.8194)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:39:38 finetune](__main__.py 1110): INFO EPOCH 6 training takes 0:02:05
[2025-05-08 10:39:52 finetune](__main__.py 1196): INFO Test: [0/12] | Time 13.263 (13.263) | Loss 0.6470 (0.6470) | Mem 16698MB
[2025-05-08 10:40:03 finetune](__main__.py 906): INFO Val | Epoch 6 | Images: 3000 | loss: 0.6405
[2025-05-08 10:40:03 finetune](__main__.py 907): INFO Val | Epoch 6 | Images: 3000 | ACC: 0.671
[2025-05-08 10:40:03 finetune](__main__.py 908): INFO Val | Epoch 6 | Images: 3000 | AP: 0.748
[2025-05-08 10:40:03 finetune](__main__.py 909): INFO Val | Epoch 6 | Images: 3000 | AUC: 0.610
[2025-05-08 10:40:03 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 10:40:03 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 10:40:03 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 10:40:03 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 10:40:03 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_6.pth saving......
[2025-05-08 10:40:03 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_6.pth saved !!!
[2025-05-08 10:40:03 finetune](__main__.py 955): INFO Epoch training time: 150.374s
[2025-05-08 10:40:03 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [0.0004523722461662516, 0.0004523722461662516]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:40:20 finetune](__main__.py 1101): INFO Train: [7/35][0/140]	eta 0:40:15 lr 0.000452	time 17.2514 (17.2514)	loss 0.6280 (0.6280)	grad_norm 0.7369 (0.7369)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:42:03 finetune](__main__.py 1101): INFO Train: [7/35][100/140]	eta 0:00:47 lr 0.000442	time 0.6952 (1.1885)	loss 0.6579 (0.6418)	grad_norm 0.6171 (0.7770)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:42:35 finetune](__main__.py 1110): INFO EPOCH 7 training takes 0:02:31
[2025-05-08 10:42:49 finetune](__main__.py 1196): INFO Test: [0/12] | Time 13.764 (13.764) | Loss 0.6430 (0.6430) | Mem 16698MB
[2025-05-08 10:43:00 finetune](__main__.py 906): INFO Val | Epoch 7 | Images: 3000 | loss: 0.6369
[2025-05-08 10:43:00 finetune](__main__.py 907): INFO Val | Epoch 7 | Images: 3000 | ACC: 0.671
[2025-05-08 10:43:00 finetune](__main__.py 908): INFO Val | Epoch 7 | Images: 3000 | AP: 0.758
[2025-05-08 10:43:00 finetune](__main__.py 909): INFO Val | Epoch 7 | Images: 3000 | AUC: 0.627
[2025-05-08 10:43:00 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 10:43:00 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 10:43:00 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 10:43:00 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 10:43:00 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_7.pth saving......
[2025-05-08 10:43:00 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_7.pth saved !!!
[2025-05-08 10:43:00 finetune](__main__.py 955): INFO Epoch training time: 177.213s
[2025-05-08 10:43:01 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [0.0004384040990879451, 0.0004384040990879451]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:43:14 finetune](__main__.py 1101): INFO Train: [8/35][0/140]	eta 0:30:29 lr 0.000438	time 13.0661 (13.0661)	loss 0.5844 (0.5844)	grad_norm 0.8272 (0.8272)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:44:36 finetune](__main__.py 1101): INFO Train: [8/35][100/140]	eta 0:00:37 lr 0.000427	time 0.6956 (0.9455)	loss 0.6266 (0.6433)	grad_norm 0.5912 (0.7587)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:45:05 finetune](__main__.py 1110): INFO EPOCH 8 training takes 0:02:04
[2025-05-08 10:45:19 finetune](__main__.py 1196): INFO Test: [0/12] | Time 13.706 (13.706) | Loss 0.6380 (0.6380) | Mem 16698MB
[2025-05-08 10:45:30 finetune](__main__.py 906): INFO Val | Epoch 8 | Images: 3000 | loss: 0.6332
[2025-05-08 10:45:30 finetune](__main__.py 907): INFO Val | Epoch 8 | Images: 3000 | ACC: 0.671
[2025-05-08 10:45:30 finetune](__main__.py 908): INFO Val | Epoch 8 | Images: 3000 | AP: 0.710
[2025-05-08 10:45:30 finetune](__main__.py 909): INFO Val | Epoch 8 | Images: 3000 | AUC: 0.565
[2025-05-08 10:45:30 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 10:45:30 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 10:45:30 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 10:45:30 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 10:45:30 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_8.pth saving......
[2025-05-08 10:45:30 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_8.pth saved !!!
[2025-05-08 10:45:30 finetune](__main__.py 955): INFO Epoch training time: 149.899s
[2025-05-08 10:45:31 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [0.0004229200394100999, 0.0004229200394100999]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:45:43 finetune](__main__.py 1101): INFO Train: [9/35][0/140]	eta 0:29:50 lr 0.000423	time 12.7920 (12.7920)	loss 0.6167 (0.6167)	grad_norm 1.0494 (1.0494)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:47:15 finetune](__main__.py 1101): INFO Train: [9/35][100/140]	eta 0:00:41 lr 0.000411	time 0.6949 (1.0298)	loss 0.6266 (0.6410)	grad_norm 0.6909 (0.7383)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:47:45 finetune](__main__.py 1110): INFO EPOCH 9 training takes 0:02:14
[2025-05-08 10:48:01 finetune](__main__.py 1196): INFO Test: [0/12] | Time 16.473 (16.473) | Loss 0.6517 (0.6517) | Mem 16698MB
[2025-05-08 10:48:12 finetune](__main__.py 906): INFO Val | Epoch 9 | Images: 3000 | loss: 0.6442
[2025-05-08 10:48:12 finetune](__main__.py 907): INFO Val | Epoch 9 | Images: 3000 | ACC: 0.671
[2025-05-08 10:48:12 finetune](__main__.py 908): INFO Val | Epoch 9 | Images: 3000 | AP: 0.684
[2025-05-08 10:48:12 finetune](__main__.py 909): INFO Val | Epoch 9 | Images: 3000 | AUC: 0.525
[2025-05-08 10:48:12 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 10:48:12 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 10:48:12 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 10:48:12 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 10:48:12 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_9.pth saving......
[2025-05-08 10:48:13 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_9.pth saved !!!
[2025-05-08 10:48:13 finetune](__main__.py 955): INFO Epoch training time: 162.297s
[2025-05-08 10:48:13 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [0.00040604473567676245, 0.00040604473567676245]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:48:28 finetune](__main__.py 1101): INFO Train: [10/35][0/140]	eta 0:35:25 lr 0.000406	time 15.1833 (15.1833)	loss 0.6467 (0.6467)	grad_norm 0.7287 (0.7287)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:49:53 finetune](__main__.py 1101): INFO Train: [10/35][100/140]	eta 0:00:39 lr 0.000393	time 0.6952 (0.9863)	loss 0.6261 (0.6421)	grad_norm 0.6354 (0.7685)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:50:22 finetune](__main__.py 1110): INFO EPOCH 10 training takes 0:02:09
[2025-05-08 10:50:33 finetune](__main__.py 1196): INFO Test: [0/12] | Time 10.915 (10.915) | Loss 0.6410 (0.6410) | Mem 16698MB
[2025-05-08 10:50:45 finetune](__main__.py 906): INFO Val | Epoch 10 | Images: 3000 | loss: 0.6353
[2025-05-08 10:50:45 finetune](__main__.py 907): INFO Val | Epoch 10 | Images: 3000 | ACC: 0.671
[2025-05-08 10:50:45 finetune](__main__.py 908): INFO Val | Epoch 10 | Images: 3000 | AP: 0.750
[2025-05-08 10:50:45 finetune](__main__.py 909): INFO Val | Epoch 10 | Images: 3000 | AUC: 0.604
[2025-05-08 10:50:45 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 10:50:45 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 10:50:45 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 10:50:45 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 10:50:45 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_10.pth saving......
[2025-05-08 10:50:46 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_10.pth saved !!!
[2025-05-08 10:50:46 finetune](__main__.py 955): INFO Epoch training time: 152.522s
[2025-05-08 10:50:46 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [0.00038791405791107557, 0.00038791405791107557]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:51:00 finetune](__main__.py 1101): INFO Train: [11/35][0/140]	eta 0:32:47 lr 0.000388	time 14.0556 (14.0556)	loss 0.6288 (0.6288)	grad_norm 0.5978 (0.5978)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:52:42 finetune](__main__.py 1101): INFO Train: [11/35][100/140]	eta 0:00:46 lr 0.000374	time 0.6951 (1.1505)	loss 0.6438 (0.6388)	grad_norm 0.6042 (0.7439)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:53:18 finetune](__main__.py 1110): INFO EPOCH 11 training takes 0:02:32
[2025-05-08 10:53:30 finetune](__main__.py 1196): INFO Test: [0/12] | Time 11.844 (11.844) | Loss 0.6429 (0.6429) | Mem 16698MB
[2025-05-08 10:53:42 finetune](__main__.py 906): INFO Val | Epoch 11 | Images: 3000 | loss: 0.6364
[2025-05-08 10:53:42 finetune](__main__.py 907): INFO Val | Epoch 11 | Images: 3000 | ACC: 0.671
[2025-05-08 10:53:42 finetune](__main__.py 908): INFO Val | Epoch 11 | Images: 3000 | AP: 0.651
[2025-05-08 10:53:42 finetune](__main__.py 909): INFO Val | Epoch 11 | Images: 3000 | AUC: 0.486
[2025-05-08 10:53:42 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 10:53:42 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 10:53:42 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 10:53:42 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 10:53:42 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_11.pth saving......
[2025-05-08 10:53:43 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_11.pth saved !!!
[2025-05-08 10:53:43 finetune](__main__.py 955): INFO Epoch training time: 177.433s
[2025-05-08 10:53:43 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [0.0003686739836697428, 0.0003686739836697428]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:53:58 finetune](__main__.py 1101): INFO Train: [12/35][0/140]	eta 0:34:08 lr 0.000369	time 14.6353 (14.6353)	loss 0.6559 (0.6559)	grad_norm 0.7161 (0.7161)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:55:25 finetune](__main__.py 1101): INFO Train: [12/35][100/140]	eta 0:00:40 lr 0.000354	time 0.6950 (1.0084)	loss 0.6443 (0.6404)	grad_norm 0.5911 (0.7471)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:55:52 finetune](__main__.py 1110): INFO EPOCH 12 training takes 0:02:09
[2025-05-08 10:56:04 finetune](__main__.py 1196): INFO Test: [0/12] | Time 11.801 (11.801) | Loss 0.6398 (0.6398) | Mem 16698MB
[2025-05-08 10:56:15 finetune](__main__.py 906): INFO Val | Epoch 12 | Images: 3000 | loss: 0.6352
[2025-05-08 10:56:15 finetune](__main__.py 907): INFO Val | Epoch 12 | Images: 3000 | ACC: 0.671
[2025-05-08 10:56:15 finetune](__main__.py 908): INFO Val | Epoch 12 | Images: 3000 | AP: 0.655
[2025-05-08 10:56:15 finetune](__main__.py 909): INFO Val | Epoch 12 | Images: 3000 | AUC: 0.500
[2025-05-08 10:56:15 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 10:56:15 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 10:56:15 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 10:56:15 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 10:56:15 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_12.pth saving......
[2025-05-08 10:56:16 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_12.pth saved !!!
[2025-05-08 10:56:16 finetune](__main__.py 955): INFO Epoch training time: 152.684s
[2025-05-08 10:56:16 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [0.0003484794227175748, 0.0003484794227175748]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:56:27 finetune](__main__.py 1101): INFO Train: [13/35][0/140]	eta 0:25:44 lr 0.000348	time 11.0312 (11.0312)	loss 0.6162 (0.6162)	grad_norm 0.8444 (0.8444)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:57:38 finetune](__main__.py 1101): INFO Train: [13/35][100/140]	eta 0:00:32 lr 0.000333	time 0.6952 (0.8092)	loss 0.6771 (0.6403)	grad_norm 1.1019 (0.7593)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:58:05 finetune](__main__.py 1110): INFO EPOCH 13 training takes 0:01:49
[2025-05-08 10:58:24 finetune](__main__.py 1196): INFO Test: [0/12] | Time 18.669 (18.669) | Loss 0.6367 (0.6367) | Mem 16698MB
[2025-05-08 10:58:35 finetune](__main__.py 906): INFO Val | Epoch 13 | Images: 3000 | loss: 0.6322
[2025-05-08 10:58:35 finetune](__main__.py 907): INFO Val | Epoch 13 | Images: 3000 | ACC: 0.671
[2025-05-08 10:58:35 finetune](__main__.py 908): INFO Val | Epoch 13 | Images: 3000 | AP: 0.770
[2025-05-08 10:58:35 finetune](__main__.py 909): INFO Val | Epoch 13 | Images: 3000 | AUC: 0.635
[2025-05-08 10:58:35 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 10:58:35 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 10:58:35 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 10:58:35 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 10:58:35 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_13.pth saving......
[2025-05-08 10:58:36 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_13.pth saved !!!
[2025-05-08 10:58:36 finetune](__main__.py 955): INFO Epoch training time: 139.681s
[2025-05-08 10:58:36 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [0.00032749296978514897, 0.00032749296978514897]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 10:58:52 finetune](__main__.py 1101): INFO Train: [14/35][0/140]	eta 0:37:44 lr 0.000327	time 16.1758 (16.1758)	loss 0.6578 (0.6578)	grad_norm 0.6322 (0.6322)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:00:32 finetune](__main__.py 1101): INFO Train: [14/35][100/140]	eta 0:00:46 lr 0.000312	time 0.6950 (1.1545)	loss 0.6169 (0.6407)	grad_norm 0.6011 (0.7467)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:01:12 finetune](__main__.py 1110): INFO EPOCH 14 training takes 0:02:36
[2025-05-08 11:01:29 finetune](__main__.py 1196): INFO Test: [0/12] | Time 17.339 (17.339) | Loss 0.6382 (0.6382) | Mem 16698MB
[2025-05-08 11:01:40 finetune](__main__.py 906): INFO Val | Epoch 14 | Images: 3000 | loss: 0.6343
[2025-05-08 11:01:40 finetune](__main__.py 907): INFO Val | Epoch 14 | Images: 3000 | ACC: 0.671
[2025-05-08 11:01:40 finetune](__main__.py 908): INFO Val | Epoch 14 | Images: 3000 | AP: 0.758
[2025-05-08 11:01:40 finetune](__main__.py 909): INFO Val | Epoch 14 | Images: 3000 | AUC: 0.621
[2025-05-08 11:01:40 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 11:01:40 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 11:01:40 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 11:01:40 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 11:01:41 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_14.pth saving......
[2025-05-08 11:01:41 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_14.pth saved !!!
[2025-05-08 11:01:41 finetune](__main__.py 955): INFO Epoch training time: 185.507s
[2025-05-08 11:01:41 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [0.00030588359545164265, 0.00030588359545164265]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:01:53 finetune](__main__.py 1101): INFO Train: [15/35][0/140]	eta 0:26:27 lr 0.000306	time 11.3411 (11.3411)	loss 0.6181 (0.6181)	grad_norm 0.7961 (0.7961)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:03:09 finetune](__main__.py 1101): INFO Train: [15/35][100/140]	eta 0:00:34 lr 0.000290	time 0.6952 (0.8658)	loss 0.6440 (0.6408)	grad_norm 0.6479 (0.7506)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:03:36 finetune](__main__.py 1110): INFO EPOCH 15 training takes 0:01:54
[2025-05-08 11:03:51 finetune](__main__.py 1196): INFO Test: [0/12] | Time 14.798 (14.798) | Loss 0.6648 (0.6648) | Mem 16698MB
[2025-05-08 11:04:02 finetune](__main__.py 906): INFO Val | Epoch 15 | Images: 3000 | loss: 0.6563
[2025-05-08 11:04:02 finetune](__main__.py 907): INFO Val | Epoch 15 | Images: 3000 | ACC: 0.671
[2025-05-08 11:04:02 finetune](__main__.py 908): INFO Val | Epoch 15 | Images: 3000 | AP: 0.713
[2025-05-08 11:04:02 finetune](__main__.py 909): INFO Val | Epoch 15 | Images: 3000 | AUC: 0.561
[2025-05-08 11:04:02 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 11:04:02 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 11:04:02 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 11:04:02 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 11:04:02 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_15.pth saving......
[2025-05-08 11:04:07 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_15.pth saved !!!
[2025-05-08 11:04:07 finetune](__main__.py 955): INFO Epoch training time: 145.145s
[2025-05-08 11:04:07 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [0.00028382528569308277, 0.00028382528569308277]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:04:19 finetune](__main__.py 1101): INFO Train: [16/35][0/140]	eta 0:29:14 lr 0.000284	time 12.5288 (12.5288)	loss 0.6507 (0.6507)	grad_norm 0.9073 (0.9073)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:05:30 finetune](__main__.py 1101): INFO Train: [16/35][100/140]	eta 0:00:33 lr 0.000268	time 0.9349 (0.8267)	loss 0.6115 (0.6399)	grad_norm 0.6963 (0.7374)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:06:00 finetune](__main__.py 1110): INFO EPOCH 16 training takes 0:01:53
[2025-05-08 11:06:14 finetune](__main__.py 1196): INFO Test: [0/12] | Time 14.177 (14.177) | Loss 0.6448 (0.6448) | Mem 16698MB
[2025-05-08 11:06:25 finetune](__main__.py 906): INFO Val | Epoch 16 | Images: 3000 | loss: 0.6377
[2025-05-08 11:06:25 finetune](__main__.py 907): INFO Val | Epoch 16 | Images: 3000 | ACC: 0.671
[2025-05-08 11:06:25 finetune](__main__.py 908): INFO Val | Epoch 16 | Images: 3000 | AP: 0.617
[2025-05-08 11:06:25 finetune](__main__.py 909): INFO Val | Epoch 16 | Images: 3000 | AUC: 0.453
[2025-05-08 11:06:25 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 11:06:25 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 11:06:25 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 11:06:25 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 11:06:25 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_16.pth saving......
[2025-05-08 11:06:26 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_16.pth saved !!!
[2025-05-08 11:06:26 finetune](__main__.py 955): INFO Epoch training time: 139.711s
[2025-05-08 11:06:26 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [0.0002614956410495695, 0.0002614956410495695]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:06:44 finetune](__main__.py 1101): INFO Train: [17/35][0/140]	eta 0:41:09 lr 0.000261	time 17.6357 (17.6357)	loss 0.6314 (0.6314)	grad_norm 0.6435 (0.6435)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:08:13 finetune](__main__.py 1101): INFO Train: [17/35][100/140]	eta 0:00:42 lr 0.000245	time 0.6951 (1.0513)	loss 0.6555 (0.6395)	grad_norm 0.6139 (0.7942)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:08:45 finetune](__main__.py 1110): INFO EPOCH 17 training takes 0:02:18
[2025-05-08 11:09:05 finetune](__main__.py 1196): INFO Test: [0/12] | Time 19.318 (19.318) | Loss 0.6392 (0.6392) | Mem 16698MB
[2025-05-08 11:09:16 finetune](__main__.py 906): INFO Val | Epoch 17 | Images: 3000 | loss: 0.6352
[2025-05-08 11:09:16 finetune](__main__.py 907): INFO Val | Epoch 17 | Images: 3000 | ACC: 0.671
[2025-05-08 11:09:16 finetune](__main__.py 908): INFO Val | Epoch 17 | Images: 3000 | AP: 0.698
[2025-05-08 11:09:16 finetune](__main__.py 909): INFO Val | Epoch 17 | Images: 3000 | AUC: 0.571
[2025-05-08 11:09:16 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 11:09:16 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 11:09:16 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 11:09:16 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 11:09:16 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_17.pth saving......
[2025-05-08 11:09:17 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_17.pth saved !!!
[2025-05-08 11:09:17 finetune](__main__.py 955): INFO Epoch training time: 170.246s
[2025-05-08 11:09:17 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [0.00023907444669015365, 0.00023907444669015365]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:09:29 finetune](__main__.py 1101): INFO Train: [18/35][0/140]	eta 0:27:44 lr 0.000239	time 11.8875 (11.8875)	loss 0.6554 (0.6554)	grad_norm 0.5974 (0.5974)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:10:57 finetune](__main__.py 1101): INFO Train: [18/35][100/140]	eta 0:00:39 lr 0.000223	time 0.6949 (0.9924)	loss 0.6481 (0.6417)	grad_norm 0.6086 (0.7524)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:11:33 finetune](__main__.py 1110): INFO EPOCH 18 training takes 0:02:15
[2025-05-08 11:11:47 finetune](__main__.py 1196): INFO Test: [0/12] | Time 14.829 (14.829) | Loss 0.6405 (0.6405) | Mem 16698MB
[2025-05-08 11:11:59 finetune](__main__.py 906): INFO Val | Epoch 18 | Images: 3000 | loss: 0.6343
[2025-05-08 11:11:59 finetune](__main__.py 907): INFO Val | Epoch 18 | Images: 3000 | ACC: 0.671
[2025-05-08 11:11:59 finetune](__main__.py 908): INFO Val | Epoch 18 | Images: 3000 | AP: 0.667
[2025-05-08 11:11:59 finetune](__main__.py 909): INFO Val | Epoch 18 | Images: 3000 | AUC: 0.526
[2025-05-08 11:11:59 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 11:11:59 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 11:11:59 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 11:11:59 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 11:11:59 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_18.pth saving......
[2025-05-08 11:12:01 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_18.pth saved !!!
[2025-05-08 11:12:01 finetune](__main__.py 955): INFO Epoch training time: 164.002s
[2025-05-08 11:12:01 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [0.00021674222488836858, 0.00021674222488836858]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:12:22 finetune](__main__.py 1101): INFO Train: [19/35][0/140]	eta 0:48:32 lr 0.000217	time 20.8004 (20.8004)	loss 0.6234 (0.6234)	grad_norm 0.6667 (0.6667)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:13:54 finetune](__main__.py 1101): INFO Train: [19/35][100/140]	eta 0:00:44 lr 0.000201	time 0.6953 (1.1191)	loss 0.6693 (0.6405)	grad_norm 0.7914 (0.7792)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:14:26 finetune](__main__.py 1110): INFO EPOCH 19 training takes 0:02:24
[2025-05-08 11:14:39 finetune](__main__.py 1196): INFO Test: [0/12] | Time 13.544 (13.544) | Loss 0.6378 (0.6378) | Mem 16698MB
[2025-05-08 11:14:51 finetune](__main__.py 906): INFO Val | Epoch 19 | Images: 3000 | loss: 0.6326
[2025-05-08 11:14:51 finetune](__main__.py 907): INFO Val | Epoch 19 | Images: 3000 | ACC: 0.671
[2025-05-08 11:14:51 finetune](__main__.py 908): INFO Val | Epoch 19 | Images: 3000 | AP: 0.714
[2025-05-08 11:14:51 finetune](__main__.py 909): INFO Val | Epoch 19 | Images: 3000 | AUC: 0.566
[2025-05-08 11:14:51 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 11:14:51 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 11:14:51 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 11:14:51 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 11:14:51 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_19.pth saving......
[2025-05-08 11:14:53 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_19.pth saved !!!
[2025-05-08 11:14:53 finetune](__main__.py 955): INFO Epoch training time: 171.837s
[2025-05-08 11:14:53 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [0.00019467878156302838, 0.00019467878156302838]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:15:09 finetune](__main__.py 1101): INFO Train: [20/35][0/140]	eta 0:38:22 lr 0.000195	time 16.4452 (16.4452)	loss 0.6278 (0.6278)	grad_norm 0.7839 (0.7839)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:16:35 finetune](__main__.py 1101): INFO Train: [20/35][100/140]	eta 0:00:40 lr 0.000179	time 0.6956 (1.0119)	loss 0.6278 (0.6400)	grad_norm 0.5946 (0.7731)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:17:03 finetune](__main__.py 1110): INFO EPOCH 20 training takes 0:02:10
[2025-05-08 11:17:18 finetune](__main__.py 1196): INFO Test: [0/12] | Time 15.157 (15.157) | Loss 0.6397 (0.6397) | Mem 16698MB
[2025-05-08 11:17:30 finetune](__main__.py 906): INFO Val | Epoch 20 | Images: 3000 | loss: 0.6342
[2025-05-08 11:17:30 finetune](__main__.py 907): INFO Val | Epoch 20 | Images: 3000 | ACC: 0.671
[2025-05-08 11:17:30 finetune](__main__.py 908): INFO Val | Epoch 20 | Images: 3000 | AP: 0.654
[2025-05-08 11:17:30 finetune](__main__.py 909): INFO Val | Epoch 20 | Images: 3000 | AUC: 0.493
[2025-05-08 11:17:30 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 11:17:30 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 11:17:30 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 11:17:30 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 11:17:30 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_20.pth saving......
[2025-05-08 11:17:30 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_20.pth saved !!!
[2025-05-08 11:17:30 finetune](__main__.py 955): INFO Epoch training time: 157.178s
[2025-05-08 11:17:30 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [0.00017306175858669432, 0.00017306175858669432]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:17:44 finetune](__main__.py 1101): INFO Train: [21/35][0/140]	eta 0:32:03 lr 0.000173	time 13.7361 (13.7361)	loss 0.6370 (0.6370)	grad_norm 0.6214 (0.6214)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:19:05 finetune](__main__.py 1101): INFO Train: [21/35][100/140]	eta 0:00:37 lr 0.000158	time 0.6952 (0.9384)	loss 0.6625 (0.6405)	grad_norm 0.6808 (0.7452)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:19:39 finetune](__main__.py 1110): INFO EPOCH 21 training takes 0:02:08
[2025-05-08 11:19:54 finetune](__main__.py 1196): INFO Test: [0/12] | Time 14.840 (14.840) | Loss 0.6400 (0.6400) | Mem 16698MB
[2025-05-08 11:20:05 finetune](__main__.py 906): INFO Val | Epoch 21 | Images: 3000 | loss: 0.6345
[2025-05-08 11:20:05 finetune](__main__.py 907): INFO Val | Epoch 21 | Images: 3000 | ACC: 0.671
[2025-05-08 11:20:05 finetune](__main__.py 908): INFO Val | Epoch 21 | Images: 3000 | AP: 0.645
[2025-05-08 11:20:05 finetune](__main__.py 909): INFO Val | Epoch 21 | Images: 3000 | AUC: 0.484
[2025-05-08 11:20:05 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 11:20:05 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 11:20:05 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 11:20:05 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 11:20:05 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_21.pth saving......
[2025-05-08 11:20:05 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_21.pth saved !!!
[2025-05-08 11:20:05 finetune](__main__.py 955): INFO Epoch training time: 154.876s
[2025-05-08 11:20:05 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [0.00015206520351776793, 0.00015206520351776793]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:20:20 finetune](__main__.py 1101): INFO Train: [22/35][0/140]	eta 0:33:34 lr 0.000152	time 14.3887 (14.3887)	loss 0.6351 (0.6351)	grad_norm 0.6200 (0.6200)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:21:46 finetune](__main__.py 1101): INFO Train: [22/35][100/140]	eta 0:00:39 lr 0.000137	time 0.6952 (0.9999)	loss 0.6464 (0.6390)	grad_norm 0.7149 (0.7799)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:22:18 finetune](__main__.py 1110): INFO EPOCH 22 training takes 0:02:13
[2025-05-08 11:22:34 finetune](__main__.py 1196): INFO Test: [0/12] | Time 16.079 (16.079) | Loss 0.6408 (0.6408) | Mem 16698MB
[2025-05-08 11:22:45 finetune](__main__.py 906): INFO Val | Epoch 22 | Images: 3000 | loss: 0.6348
[2025-05-08 11:22:45 finetune](__main__.py 907): INFO Val | Epoch 22 | Images: 3000 | ACC: 0.671
[2025-05-08 11:22:45 finetune](__main__.py 908): INFO Val | Epoch 22 | Images: 3000 | AP: 0.647
[2025-05-08 11:22:45 finetune](__main__.py 909): INFO Val | Epoch 22 | Images: 3000 | AUC: 0.480
[2025-05-08 11:22:45 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 11:22:45 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 11:22:45 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 11:22:45 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 11:22:45 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_22.pth saving......
[2025-05-08 11:22:46 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_22.pth saved !!!
[2025-05-08 11:22:46 finetune](__main__.py 955): INFO Epoch training time: 160.730s
[2025-05-08 11:22:46 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [0.00013185816827188996, 0.00013185816827188996]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:23:02 finetune](__main__.py 1101): INFO Train: [23/35][0/140]	eta 0:37:36 lr 0.000132	time 16.1173 (16.1173)	loss 0.6846 (0.6846)	grad_norm 1.0580 (1.0580)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:25:02 finetune](__main__.py 1101): INFO Train: [23/35][100/140]	eta 0:00:53 lr 0.000118	time 0.6960 (1.3488)	loss 0.6360 (0.6368)	grad_norm 0.6592 (0.7529)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:25:48 finetune](__main__.py 1110): INFO EPOCH 23 training takes 0:03:01
[2025-05-08 11:26:02 finetune](__main__.py 1196): INFO Test: [0/12] | Time 13.704 (13.704) | Loss 0.6406 (0.6406) | Mem 16698MB
[2025-05-08 11:26:13 finetune](__main__.py 906): INFO Val | Epoch 23 | Images: 3000 | loss: 0.6345
[2025-05-08 11:26:13 finetune](__main__.py 907): INFO Val | Epoch 23 | Images: 3000 | ACC: 0.671
[2025-05-08 11:26:13 finetune](__main__.py 908): INFO Val | Epoch 23 | Images: 3000 | AP: 0.656
[2025-05-08 11:26:13 finetune](__main__.py 909): INFO Val | Epoch 23 | Images: 3000 | AUC: 0.489
[2025-05-08 11:26:13 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 11:26:13 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 11:26:13 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 11:26:13 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 11:26:13 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_23.pth saving......
[2025-05-08 11:26:13 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_23.pth saved !!!
[2025-05-08 11:26:13 finetune](__main__.py 955): INFO Epoch training time: 207.427s
[2025-05-08 11:26:14 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [0.00011260334801531575, 0.00011260334801531575]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:26:29 finetune](__main__.py 1101): INFO Train: [24/35][0/140]	eta 0:35:38 lr 0.000112	time 15.2756 (15.2756)	loss 0.6873 (0.6873)	grad_norm 1.1083 (1.1083)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:27:56 finetune](__main__.py 1101): INFO Train: [24/35][100/140]	eta 0:00:40 lr 0.000099	time 0.6953 (1.0181)	loss 0.6067 (0.6381)	grad_norm 0.6281 (0.7709)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:28:37 finetune](__main__.py 1110): INFO EPOCH 24 training takes 0:02:23
[2025-05-08 11:28:59 finetune](__main__.py 1196): INFO Test: [0/12] | Time 21.946 (21.946) | Loss 0.6410 (0.6410) | Mem 16698MB
[2025-05-08 11:29:11 finetune](__main__.py 906): INFO Val | Epoch 24 | Images: 3000 | loss: 0.6347
[2025-05-08 11:29:11 finetune](__main__.py 907): INFO Val | Epoch 24 | Images: 3000 | ACC: 0.671
[2025-05-08 11:29:11 finetune](__main__.py 908): INFO Val | Epoch 24 | Images: 3000 | AP: 0.688
[2025-05-08 11:29:11 finetune](__main__.py 909): INFO Val | Epoch 24 | Images: 3000 | AUC: 0.522
[2025-05-08 11:29:11 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 11:29:11 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 11:29:11 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 11:29:11 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 11:29:11 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_24.pth saving......
[2025-05-08 11:29:11 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_24.pth saved !!!
[2025-05-08 11:29:11 finetune](__main__.py 955): INFO Epoch training time: 177.855s
[2025-05-08 11:29:11 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [9.445577123910035e-05, 9.445577123910035e-05]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:29:30 finetune](__main__.py 1101): INFO Train: [25/35][0/140]	eta 0:44:09 lr 0.000094	time 18.9243 (18.9243)	loss 0.6566 (0.6566)	grad_norm 0.7185 (0.7185)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:31:16 finetune](__main__.py 1101): INFO Train: [25/35][100/140]	eta 0:00:49 lr 0.000082	time 0.6952 (1.2306)	loss 0.6280 (0.6398)	grad_norm 0.5517 (0.7470)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:31:44 finetune](__main__.py 1110): INFO EPOCH 25 training takes 0:02:32
[2025-05-08 11:31:57 finetune](__main__.py 1196): INFO Test: [0/12] | Time 13.128 (13.128) | Loss 0.6421 (0.6421) | Mem 16698MB
[2025-05-08 11:32:10 finetune](__main__.py 906): INFO Val | Epoch 25 | Images: 3000 | loss: 0.6356
[2025-05-08 11:32:10 finetune](__main__.py 907): INFO Val | Epoch 25 | Images: 3000 | ACC: 0.671
[2025-05-08 11:32:10 finetune](__main__.py 908): INFO Val | Epoch 25 | Images: 3000 | AP: 0.684
[2025-05-08 11:32:10 finetune](__main__.py 909): INFO Val | Epoch 25 | Images: 3000 | AUC: 0.519
[2025-05-08 11:32:10 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 11:32:10 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 11:32:10 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 11:32:10 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 11:32:10 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_25.pth saving......
[2025-05-08 11:32:11 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_25.pth saved !!!
[2025-05-08 11:32:11 finetune](__main__.py 955): INFO Epoch training time: 179.461s
[2025-05-08 11:32:11 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [7.756155156084345e-05, 7.756155156084345e-05]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:32:25 finetune](__main__.py 1101): INFO Train: [26/35][0/140]	eta 0:32:48 lr 0.000077	time 14.0581 (14.0581)	loss 0.6263 (0.6263)	grad_norm 0.6168 (0.6168)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:33:54 finetune](__main__.py 1101): INFO Train: [26/35][100/140]	eta 0:00:40 lr 0.000066	time 0.6952 (1.0142)	loss 0.6190 (0.6390)	grad_norm 0.7798 (0.7523)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:34:21 finetune](__main__.py 1110): INFO EPOCH 26 training takes 0:02:09
[2025-05-08 11:34:39 finetune](__main__.py 1196): INFO Test: [0/12] | Time 18.231 (18.231) | Loss 0.6397 (0.6397) | Mem 16698MB
[2025-05-08 11:34:50 finetune](__main__.py 906): INFO Val | Epoch 26 | Images: 3000 | loss: 0.6338
[2025-05-08 11:34:50 finetune](__main__.py 907): INFO Val | Epoch 26 | Images: 3000 | ACC: 0.671
[2025-05-08 11:34:50 finetune](__main__.py 908): INFO Val | Epoch 26 | Images: 3000 | AP: 0.675
[2025-05-08 11:34:50 finetune](__main__.py 909): INFO Val | Epoch 26 | Images: 3000 | AUC: 0.516
[2025-05-08 11:34:50 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 11:34:50 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 11:34:50 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 11:34:50 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 11:34:50 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_26.pth saving......
[2025-05-08 11:34:51 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_26.pth saved !!!
[2025-05-08 11:34:51 finetune](__main__.py 955): INFO Epoch training time: 159.785s
[2025-05-08 11:34:51 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [6.205671130375409e-05, 6.205671130375409e-05]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:35:04 finetune](__main__.py 1101): INFO Train: [27/35][0/140]	eta 0:30:03 lr 0.000062	time 12.8798 (12.8798)	loss 0.6509 (0.6509)	grad_norm 0.6267 (0.6267)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:36:24 finetune](__main__.py 1101): INFO Train: [27/35][100/140]	eta 0:00:36 lr 0.000052	time 1.3561 (0.9208)	loss 0.6474 (0.6400)	grad_norm 0.6272 (0.7362)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:37:00 finetune](__main__.py 1110): INFO EPOCH 27 training takes 0:02:08
[2025-05-08 11:37:18 finetune](__main__.py 1196): INFO Test: [0/12] | Time 18.959 (18.959) | Loss 0.6441 (0.6441) | Mem 16698MB
[2025-05-08 11:37:30 finetune](__main__.py 906): INFO Val | Epoch 27 | Images: 3000 | loss: 0.6371
[2025-05-08 11:37:30 finetune](__main__.py 907): INFO Val | Epoch 27 | Images: 3000 | ACC: 0.671
[2025-05-08 11:37:30 finetune](__main__.py 908): INFO Val | Epoch 27 | Images: 3000 | AP: 0.670
[2025-05-08 11:37:30 finetune](__main__.py 909): INFO Val | Epoch 27 | Images: 3000 | AUC: 0.513
[2025-05-08 11:37:30 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 11:37:30 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 11:37:30 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 11:37:30 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 11:37:30 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_27.pth saving......
[2025-05-08 11:37:31 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_27.pth saved !!!
[2025-05-08 11:37:31 finetune](__main__.py 955): INFO Epoch training time: 160.387s
[2025-05-08 11:37:32 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [4.8066086324883945e-05, 4.8066086324883945e-05]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:37:49 finetune](__main__.py 1101): INFO Train: [28/35][0/140]	eta 0:41:29 lr 0.000048	time 17.7855 (17.7855)	loss 0.6182 (0.6182)	grad_norm 0.6644 (0.6644)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:39:16 finetune](__main__.py 1101): INFO Train: [28/35][100/140]	eta 0:00:41 lr 0.000039	time 0.6950 (1.0327)	loss 0.6313 (0.6386)	grad_norm 0.6326 (0.7567)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:39:49 finetune](__main__.py 1110): INFO EPOCH 28 training takes 0:02:17
[2025-05-08 11:40:06 finetune](__main__.py 1196): INFO Test: [0/12] | Time 16.685 (16.685) | Loss 0.6411 (0.6411) | Mem 16698MB
[2025-05-08 11:40:18 finetune](__main__.py 906): INFO Val | Epoch 28 | Images: 3000 | loss: 0.6347
[2025-05-08 11:40:18 finetune](__main__.py 907): INFO Val | Epoch 28 | Images: 3000 | ACC: 0.671
[2025-05-08 11:40:18 finetune](__main__.py 908): INFO Val | Epoch 28 | Images: 3000 | AP: 0.659
[2025-05-08 11:40:18 finetune](__main__.py 909): INFO Val | Epoch 28 | Images: 3000 | AUC: 0.503
[2025-05-08 11:40:18 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 11:40:18 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 11:40:18 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 11:40:18 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 11:40:18 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_28.pth saving......
[2025-05-08 11:40:18 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_28.pth saved !!!
[2025-05-08 11:40:18 finetune](__main__.py 955): INFO Epoch training time: 166.768s
[2025-05-08 11:40:18 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [3.5702320910208554e-05, 3.5702320910208554e-05]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:40:31 finetune](__main__.py 1101): INFO Train: [29/35][0/140]	eta 0:29:53 lr 0.000036	time 12.8094 (12.8094)	loss 0.6432 (0.6432)	grad_norm 0.6356 (0.6356)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:41:57 finetune](__main__.py 1101): INFO Train: [29/35][100/140]	eta 0:00:39 lr 0.000028	time 0.6951 (0.9779)	loss 0.6332 (0.6371)	grad_norm 0.6018 (0.7687)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:42:33 finetune](__main__.py 1110): INFO EPOCH 29 training takes 0:02:14
[2025-05-08 11:42:52 finetune](__main__.py 1196): INFO Test: [0/12] | Time 19.063 (19.063) | Loss 0.6400 (0.6400) | Mem 16698MB
[2025-05-08 11:43:03 finetune](__main__.py 906): INFO Val | Epoch 29 | Images: 3000 | loss: 0.6339
[2025-05-08 11:43:03 finetune](__main__.py 907): INFO Val | Epoch 29 | Images: 3000 | ACC: 0.671
[2025-05-08 11:43:03 finetune](__main__.py 908): INFO Val | Epoch 29 | Images: 3000 | AP: 0.668
[2025-05-08 11:43:03 finetune](__main__.py 909): INFO Val | Epoch 29 | Images: 3000 | AUC: 0.516
[2025-05-08 11:43:03 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 11:43:03 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 11:43:03 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 11:43:03 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 11:43:03 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_29.pth saving......
[2025-05-08 11:43:04 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_29.pth saved !!!
[2025-05-08 11:43:04 finetune](__main__.py 955): INFO Epoch training time: 165.381s
[2025-05-08 11:43:04 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [2.5064960829070606e-05, 2.5064960829070606e-05]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:43:20 finetune](__main__.py 1101): INFO Train: [30/35][0/140]	eta 0:36:30 lr 0.000025	time 15.6455 (15.6455)	loss 0.6403 (0.6403)	grad_norm 0.5861 (0.5861)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:45:01 finetune](__main__.py 1101): INFO Train: [30/35][100/140]	eta 0:00:46 lr 0.000019	time 0.6949 (1.1557)	loss 0.5884 (0.6395)	grad_norm 1.2182 (0.7737)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:45:37 finetune](__main__.py 1110): INFO EPOCH 30 training takes 0:02:33
[2025-05-08 11:45:54 finetune](__main__.py 1196): INFO Test: [0/12] | Time 16.460 (16.460) | Loss 0.6406 (0.6406) | Mem 16698MB
[2025-05-08 11:46:05 finetune](__main__.py 906): INFO Val | Epoch 30 | Images: 3000 | loss: 0.6343
[2025-05-08 11:46:05 finetune](__main__.py 907): INFO Val | Epoch 30 | Images: 3000 | ACC: 0.671
[2025-05-08 11:46:05 finetune](__main__.py 908): INFO Val | Epoch 30 | Images: 3000 | AP: 0.669
[2025-05-08 11:46:05 finetune](__main__.py 909): INFO Val | Epoch 30 | Images: 3000 | AUC: 0.519
[2025-05-08 11:46:05 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 11:46:05 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 11:46:05 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 11:46:05 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 11:46:05 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_30.pth saving......
[2025-05-08 11:46:05 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_30.pth saved !!!
[2025-05-08 11:46:05 finetune](__main__.py 955): INFO Epoch training time: 181.069s
[2025-05-08 11:46:05 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [1.6239651850176943e-05, 1.6239651850176943e-05]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:46:18 finetune](__main__.py 1101): INFO Train: [31/35][0/140]	eta 0:29:17 lr 0.000016	time 12.5523 (12.5523)	loss 0.6183 (0.6183)	grad_norm 0.6547 (0.6547)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 65536.0
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:47:42 finetune](__main__.py 1101): INFO Train: [31/35][100/140]	eta 0:00:38 lr 0.000011	time 0.6952 (0.9555)	loss 0.6291 (0.6370)	grad_norm 0.6368 (inf)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:48:13 finetune](__main__.py 1110): INFO EPOCH 31 training takes 0:02:07
[2025-05-08 11:48:31 finetune](__main__.py 1196): INFO Test: [0/12] | Time 17.756 (17.756) | Loss 0.6398 (0.6398) | Mem 16698MB
[2025-05-08 11:48:44 finetune](__main__.py 906): INFO Val | Epoch 31 | Images: 3000 | loss: 0.6337
[2025-05-08 11:48:44 finetune](__main__.py 907): INFO Val | Epoch 31 | Images: 3000 | ACC: 0.671
[2025-05-08 11:48:44 finetune](__main__.py 908): INFO Val | Epoch 31 | Images: 3000 | AP: 0.673
[2025-05-08 11:48:44 finetune](__main__.py 909): INFO Val | Epoch 31 | Images: 3000 | AUC: 0.523
[2025-05-08 11:48:44 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 11:48:44 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 11:48:44 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 11:48:44 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 11:48:44 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_31.pth saving......
[2025-05-08 11:48:45 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_31.pth saved !!!
[2025-05-08 11:48:45 finetune](__main__.py 955): INFO Epoch training time: 159.541s
[2025-05-08 11:48:45 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [9.297450172228017e-06, 9.297450172228017e-06]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:49:04 finetune](__main__.py 1101): INFO Train: [32/35][0/140]	eta 0:45:17 lr 0.000009	time 19.4121 (19.4121)	loss 0.6569 (0.6569)	grad_norm 0.7298 (0.7298)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:50:33 finetune](__main__.py 1101): INFO Train: [32/35][100/140]	eta 0:00:42 lr 0.000005	time 0.6955 (1.0698)	loss 0.6401 (0.6388)	grad_norm 0.6357 (0.7837)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:51:15 finetune](__main__.py 1110): INFO EPOCH 32 training takes 0:02:29
[2025-05-08 11:51:29 finetune](__main__.py 1196): INFO Test: [0/12] | Time 14.468 (14.468) | Loss 0.6398 (0.6398) | Mem 16698MB
[2025-05-08 11:51:41 finetune](__main__.py 906): INFO Val | Epoch 32 | Images: 3000 | loss: 0.6337
[2025-05-08 11:51:41 finetune](__main__.py 907): INFO Val | Epoch 32 | Images: 3000 | ACC: 0.671
[2025-05-08 11:51:41 finetune](__main__.py 908): INFO Val | Epoch 32 | Images: 3000 | AP: 0.673
[2025-05-08 11:51:41 finetune](__main__.py 909): INFO Val | Epoch 32 | Images: 3000 | AUC: 0.523
[2025-05-08 11:51:41 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 11:51:41 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 11:51:41 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 11:51:41 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 11:51:41 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_32.pth saving......
[2025-05-08 11:51:42 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_32.pth saved !!!
[2025-05-08 11:51:42 finetune](__main__.py 955): INFO Epoch training time: 176.517s
[2025-05-08 11:51:42 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [4.294250321186126e-06, 4.294250321186126e-06]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:52:02 finetune](__main__.py 1101): INFO Train: [33/35][0/140]	eta 0:46:28 lr 0.000004	time 19.9201 (19.9201)	loss 0.6329 (0.6329)	grad_norm 0.6594 (0.6594)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:53:28 finetune](__main__.py 1101): INFO Train: [33/35][100/140]	eta 0:00:42 lr 0.000002	time 0.6954 (1.0504)	loss 0.6442 (0.6379)	grad_norm 0.6790 (0.7371)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:53:59 finetune](__main__.py 1110): INFO EPOCH 33 training takes 0:02:17
[2025-05-08 11:54:17 finetune](__main__.py 1196): INFO Test: [0/12] | Time 17.543 (17.543) | Loss 0.6398 (0.6398) | Mem 16698MB
[2025-05-08 11:54:28 finetune](__main__.py 906): INFO Val | Epoch 33 | Images: 3000 | loss: 0.6337
[2025-05-08 11:54:28 finetune](__main__.py 907): INFO Val | Epoch 33 | Images: 3000 | ACC: 0.671
[2025-05-08 11:54:28 finetune](__main__.py 908): INFO Val | Epoch 33 | Images: 3000 | AP: 0.673
[2025-05-08 11:54:28 finetune](__main__.py 909): INFO Val | Epoch 33 | Images: 3000 | AUC: 0.523
[2025-05-08 11:54:28 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 11:54:28 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 11:54:28 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 11:54:28 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 11:54:28 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_33.pth saving......
[2025-05-08 11:54:28 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_33.pth saved !!!
[2025-05-08 11:54:28 finetune](__main__.py 955): INFO Epoch training time: 166.730s
[2025-05-08 11:54:29 finetune](__main__.py 983): INFO Current learning rate for different parameter groups: [1.2703351204180297e-06, 1.2703351204180297e-06]
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:54:50 finetune](__main__.py 1101): INFO Train: [34/35][0/140]	eta 0:50:18 lr 0.000001	time 21.5583 (21.5583)	loss 0.6265 (0.6265)	grad_norm 0.6848 (0.6848)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:57:08 finetune](__main__.py 1101): INFO Train: [34/35][100/140]	eta 0:01:03 lr 0.000000	time 0.6958 (1.5760)	loss 0.6273 (0.6379)	grad_norm 0.6634 (0.7533)	mem 16698MB
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
Input shape: torch.Size([192, 3, 224, 896])
[2025-05-08 11:58:08 finetune](__main__.py 1110): INFO EPOCH 34 training takes 0:03:39
[2025-05-08 11:58:41 finetune](__main__.py 1196): INFO Test: [0/12] | Time 33.610 (33.610) | Loss 0.6398 (0.6398) | Mem 16698MB
[2025-05-08 11:58:52 finetune](__main__.py 906): INFO Val | Epoch 34 | Images: 3000 | loss: 0.6337
[2025-05-08 11:58:52 finetune](__main__.py 907): INFO Val | Epoch 34 | Images: 3000 | ACC: 0.671
[2025-05-08 11:58:52 finetune](__main__.py 908): INFO Val | Epoch 34 | Images: 3000 | AP: 0.673
[2025-05-08 11:58:52 finetune](__main__.py 909): INFO Val | Epoch 34 | Images: 3000 | AUC: 0.523
[2025-05-08 11:58:52 finetune](__main__.py 920): INFO Val | Min loss: 0.6308 | Epoch: 1
[2025-05-08 11:58:52 finetune](__main__.py 922): INFO Val | Max ACC: 0.671 | Epoch: 1
[2025-05-08 11:58:52 finetune](__main__.py 924): INFO Val | Max AP: 0.794 | Epoch: 1
[2025-05-08 11:58:52 finetune](__main__.py 926): INFO Val | Max AUC: 0.637 | Epoch: 1
[2025-05-08 11:58:52 finetune](utils.py 77): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_34.pth saving......
[2025-05-08 11:58:53 finetune](utils.py 79): INFO /home/pnair/spai/output/train/finetune/spai/ckpt_epoch_34.pth saved !!!
[2025-05-08 11:58:53 finetune](__main__.py 955): INFO Epoch training time: 264.472s
[2025-05-08 11:58:53 finetune](__main__.py 964): INFO Overall training time: 1:45:01
[neptune] [info   ] Shutting down background jobs, please wait a moment...
[neptune] [info   ] Done!
[neptune] [info   ] Waiting for the remaining 2 operations to synchronize with Neptune. Do not kill this process.
[neptune] [info   ] All 2 operations synced, thanks for waiting!
[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/spai/beast-mode/e/BEAS-22/metadata

JOB STATISTICS
==============
Job ID: 11641929
Cluster: snellius
User/Group: pnair/pnair
State: RUNNING
Nodes: 1
Cores per node: 16
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 1-04:10:40 core-walltime
Job Wall-clock time: 01:45:40
Memory Utilized: 0.00 MB
Memory Efficiency: 0.00% of 180.00 GB (180.00 GB/node)
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
